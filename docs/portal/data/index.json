{
  "api": {
    "name": "Runtime API",
    "tags": [
      "enum"
    ],
    "help": "The runtime library or container to use for inferencing."
  },
  "transformers": {
    "name": "Hugging Face Transformers",
    "tags": [
      "api"
    ]
  },
  "mlc": {
    "name": "MLC",
    "tags": [
      "api"
    ]
  },
  "trt_llm": {
    "name": "TensorRT-LLM",
    "tags": [
      "api"
    ]
  },
  "vllm": {
    "name": "vLLM",
    "tags": [
      "api"
    ]
  },
  "llama_cpp": {
    "name": "llama.cpp",
    "tags": [
      "api"
    ]
  },
  "ollama": {
    "name": "ollama",
    "tags": [
      "api"
    ]
  },
  "tokens_per_second": {
    "name": "tokens per second",
    "units": "tokens/sec",
    "units_short": "t/s",
    "tags": [
      "number"
    ]
  },
  "decode": {
    "name": "Decode Generation Rate",
    "tags": [
      "tokens_per_second"
    ]
  },
  "prefill": {
    "name": "Context Prefill Rate",
    "tags": [
      "tokens_per_second"
    ]
  },
  "memory": {
    "name": "Memory",
    "units": "MB",
    "tags": [
      "number"
    ]
  },
  "models": {
    "name": "Models",
    "tags": []
  },
  "llm": {
    "name": "Language Models (LLM / SLM)",
    "tags": [
      "models"
    ],
    "max_batch_size": 1,
    "max_context_len": null,
    "prefill_chunk": null,
    "chat_template": null,
    "hf_token": null,
    "cache_dir": "/mnt/nvme/cache",
    "property_order": [
      "url",
      "container_image",
      "quantization",
      "max_batch_size",
      "max_context_len",
      "prefill_chunk",
      "chat_template",
      "hf_token",
      "cache_dir",
      "container_cmd",
      "container_options",
      "server_host",
      "auto_update"
    ]
  },
  "max_batch_size": {
    "name": "Max Batch Size",
    "tags": [
      "number"
    ],
    "help": "The maximum number of generation requests to handle in parallel at one time."
  },
  "max_context_len": {
    "name": "Max Context Len",
    "tags": [
      "number"
    ],
    "help": "The maximum number of tokens in the chat history, including any system instruction, prompt, and future reply. Reduce this from the model's default to decrease memory usage. This can be left unset, and the model's default will be used."
  },
  "prefill_chunk": {
    "name": "Prefill Chunk Len",
    "tags": [
      "number"
    ],
    "help": "The maximum number of input tokens that can be prefilled into the KV cache at once. Longer prompts are prefilled in multiple batches.\nReduce this from the model's default to decrease memory usage."
  },
  "chat_template": {
    "name": "Chat Template",
    "tags": [
      "string"
    ],
    "placeholder": "<default>",
    "help": "Manually set the model's conversation template.  Normally this will be attempted to be determined automatically, but in some cases needs set and is specific to runtime APIs and model types."
  },
  "tensor_parallel": {
    "name": "Tensor Parallel",
    "tags": [
      "number"
    ],
    "help": "The number of GPUs to split the model across (for multi-GPU systems)"
  },
  "cache_dir": {
    "name": "Cache Dir",
    "tags": [
      "path"
    ],
    "help": "Path on the server's native filesystem that will be mounted into the container\nfor saving the models.\nIt is recommended this be relocated to NVME storage."
  },
  "quantization": {
    "name": "Quantization API",
    "tags": [
      "enum"
    ],
    "help": "The inference API and type of quantization used."
  },
  "q4f16_ft": {
    "name": "q4f16_ft (MLC)",
    "tags": [
      "quantization",
      "mlc"
    ]
  },
  "q4f16_0": {
    "name": "q4f16_0 (MLC)",
    "tags": [
      "quantization",
      "mlc"
    ]
  },
  "q4f16_1": {
    "name": "q4f16_1 (MLC)",
    "tags": [
      "quantization",
      "mlc"
    ]
  },
  "q4f32_1": {
    "name": "q4f32_1 (MLC)",
    "tags": [
      "quantization",
      "mlc"
    ]
  },
  "q4f16_2": {
    "name": "q4f16_2 (MLC)",
    "tags": [
      "quantization",
      "mlc"
    ]
  },
  "q4f16_awq": {
    "name": "q4f16_awq (MLC)",
    "tags": [
      "quantization",
      "mlc"
    ]
  },
  "e5m2_f16": {
    "name": "e5m2_f16 (MLC)",
    "tags": [
      "quantization",
      "mlc"
    ]
  },
  "e4m3_f16": {
    "name": "e4m3_f16 (MLC)",
    "tags": [
      "quantization",
      "mlc"
    ]
  },
  "e4m3_f16_max": {
    "name": "e4m3_f16_max (MLC)",
    "tags": [
      "quantization",
      "mlc"
    ]
  },
  "q4_k_m": {
    "name": "Q4_K_M (llama.cpp)",
    "tags": [
      "quantization",
      "llama_cpp"
    ]
  },
  "q4_k_l": {
    "name": "Q4_K_L (llama.cpp)",
    "tags": [
      "quantization",
      "llama_cpp"
    ]
  },
  "q5_k_s": {
    "name": "Q5_K_S (llama.cpp)",
    "tags": [
      "quantization",
      "llama_cpp"
    ]
  },
  "q5_k_m": {
    "name": "Q5_K_M (llama.cpp)",
    "tags": [
      "quantization",
      "llama_cpp"
    ]
  },
  "q5_k_l": {
    "name": "Q5_K_L (llama.cpp)",
    "tags": [
      "quantization",
      "llama_cpp"
    ]
  },
  "q6_k": {
    "name": "Q6_K (llama.cpp)",
    "tags": [
      "quantization",
      "llama_cpp"
    ]
  },
  "jetson": {
    "name": "Jetson",
    "tags": []
  },
  "orin-nano": {
    "name": "Orin Nano",
    "tags": [
      "jetson"
    ],
    "pin": true
  },
  "orin-nx": {
    "name": "Orin NX",
    "tags": [
      "jetson"
    ],
    "pin": true
  },
  "agx-orin": {
    "name": "AGX Orin",
    "tags": [
      "jetson"
    ],
    "pin": true
  },
  "orin": {
    "tags": [
      "agx-orin",
      "orin-nx",
      "orin-nano"
    ]
  },
  "property": {
    "name": "property",
    "tags": []
  },
  "number": {
    "name": "number",
    "tags": [
      "property"
    ]
  },
  "enum": {
    "name": "enum",
    "tags": [
      "property"
    ]
  },
  "bool": {
    "name": "bool",
    "tags": [
      "property"
    ]
  },
  "string": {
    "name": "string",
    "tags": [
      "property"
    ]
  },
  "path": {
    "name": "Path",
    "tags": [
      "string"
    ],
    "help": "A local path on the server."
  },
  "url": {
    "name": "Path or URL",
    "tags": [
      "string"
    ],
    "help": "URL of the model repo or local path on the server.\nIf needed, the model will be downloaded to the cache directory and quantized.\nThis location may also refer to model weights that have already been quantized."
  },
  "passkey": {
    "name": "Password, API Key, or Access Token",
    "tags": [
      "string"
    ]
  },
  "l4t": {
    "name": "Linux4Tegra (JetPack)",
    "tags": [
      "amd64"
    ]
  },
  "l4t-r35": {
    "name": "JetPack 5.1 (L4T R35)",
    "tags": [
      "l4t",
      "ubuntu-20.04",
      "agx-orin",
      "orin-nx"
    ]
  },
  "l4t-r36": {
    "name": "JetPack 6.1 (L4T R36)",
    "tags": [
      "l4t",
      "ubuntu-22.04",
      "agx-orin",
      "orin-nx"
    ]
  },
  "ubuntu": {
    "name": "Ubuntu",
    "tags": []
  },
  "ubuntu-20.04": {
    "name": "Ubuntu 20.04",
    "tags": [
      "ubuntu"
    ]
  },
  "ubuntu-22.04": {
    "name": "Ubuntu 22.04",
    "tags": [
      "ubuntu"
    ]
  },
  "ubuntu-24.04": {
    "name": "Ubuntu 24.04",
    "tags": [
      "ubuntu"
    ]
  },
  "env": {
    "name": "environment",
    "tags": []
  },
  "hf_token": {
    "name": "HF Token",
    "tags": [
      "passkey"
    ],
    "placeholder": [
      "<HuggingFace API key>"
    ],
    "help": "Your $HF_TOKEN or API key used for access to gated models on HuggingFace Hub.\nThis is only needed if you are downloading a private model or under access control.\nFor example, original 16-bit Llama weights. Quants do not typically need login."
  },
  "CUDA_VISIBLE_DEVICES": {
    "name": "CUDA Devices",
    "tags": [
      "string",
      "env"
    ],
    "help": "A comma-separated list of the GPU device indexes or UUIDs to enable.\nThis is the CUDA_VISIBLE_DEVICES environment variable and --gpus option in Docker.\nFor Jetson or other single-GPU systems, this should remain set to 0, which indicates the first detected GPU.\nClearing thie field with a blank input will result in container being run without CUDA enabled."
  },
  "arm64": {
    "name": "ARM64 (Jetson)",
    "tags": []
  },
  "amd64": {
    "name": "AMD64 (x86_64 + CUDA dGPU)",
    "tags": []
  },
  "llama_cpp:r35": {
    "name": "dustynv/llama_cpp:0.3.5-r35.4.1",
    "tags": [
      "container",
      "llama_cpp",
      "l4t-r35"
    ]
  },
  "llama_cpp:jp6": {
    "name": "dustynv/llama_cpp:r36.4.0",
    "container_image": "dustynv/llama_cpp:r36.4.0",
    "container_cmd": "$OPTIONS $IMAGE sudonim serve $ARGS",
    "container_options": "-it --rm",
    "server_host": "0.0.0.0:9000",
    "tags": [
      "container",
      "llama_cpp",
      "l4t-r36"
    ]
  },
  "container": {
    "name": "Docker Container",
    "tags": [],
    "container_options": null,
    "container_image": null,
    "container_cmd": null,
    "auto_update": null,
    "CUDA_VISIBLE_DEVICES": "all"
  },
  "container_image": {
    "name": "Container Image",
    "tags": [
      "string"
    ],
    "help": "Specify the container image to run and launch the server.\nOn Jetson, pick a tag that is compatible with your version of JetPack.\nFor example, L4T r36.4.0 images are compatible with JetPack 6.1 and 6.2.\nThese are built from jetson-containers with CUDA and are on DockerHub."
  },
  "container_options": {
    "name": "Docker Options",
    "tags": [
      "string"
    ],
    "help": "These are extra prefix flags that get passed to 'docker run' when starting the container.  These are the arguments that come before the container image name, for example --volume ~/workspace:/workspace --env WORKSPACE=/workspace"
  },
  "container_cmd": {
    "name": "Docker Run Cmd",
    "tags": [
      "string"
    ],
    "help": "Template that builds the 'docker run' command from $OPTIONS $IMAGE $ARGS\nYou can change the startup command or arguments with this."
  },
  "auto_update": {
    "name": "Auto Update",
    "tags": [
      "string"
    ],
    "options": [
      "on",
      "off"
    ],
    "help": "When set to 'on', will automatically pull the latest container on start-up."
  },
  "server_host": {
    "name": "Server IP / Port",
    "tags": [
      "string"
    ],
    "help": "The server's hostname/IP and port that it is listening on for incoming requests.\n0.0.0.0 will listen on all network interfaces (127.0.0.1 from localhost only)\nThis IP address also gets populated in the examples, so set it to your device."
  },
  "mlc:jp6": {
    "name": "dustynv/mlc:r36.4.0",
    "container_image": "dustynv/mlc:r36.4.0",
    "container_cmd": "$OPTIONS $IMAGE sudonim serve $ARGS",
    "container_options": "-it --rm",
    "server_host": "0.0.0.0:9000",
    "tags": [
      "container",
      "mlc",
      "l4t-r36"
    ]
  },
  "deepseek-r1-distill": {
    "name": "DeepSeek R1",
    "header": "deepseek-header",
    "url": "hf.co/deepseek-ai/DeepSeek-R1-Distill",
    "max_context_len": {
      "placeholder": 131072
    },
    "prefill_chunk": {
      "placeholder": 8192
    },
    "tags": [
      "llm"
    ],
    "links": {
      "deepseek": {
        "name": "DeepSeek",
        "url": "https://www.deepseek.com/"
      },
      "hf": {
        "name": "Hugging Face",
        "color": "yellow",
        "url": "hf.co/deepseek-ai/DeepSeek-R1-Distill-Llama-70B"
      }
    }
  },
  "deepseek-r1-distill-qwen-1.5b": {
    "name": "DeepSeek R1 Qwen-1.5B",
    "tags": [
      "deepseek-r1-distill",
      "orin"
    ],
    "chat_template": "deepseek_r1_qwen",
    "url": "hf.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B",
    "links": {
      "deepseek": {
        "name": "DeepSeek",
        "url": "https://www.deepseek.com/"
      },
      "hf": {
        "name": "Hugging Face",
        "color": "yellow",
        "url": "hf.co/deepseek-ai/DeepSeek-R1-Distill-Llama-70B"
      }
    },
    "created_at": "2025-01-20 09:04:18+00:00",
    "last_modified": "2025-01-26 09:15:27+00:00"
  },
  "deepseek-r1-distill-qwen-1.5b-q4f16_ft-mlc-jp6": {
    "title": "DeepSeek R1 Qwen-1.5B \u276f MLC q4f16_ft \u276f JetPack 6.1+",
    "quantization": "q4f16_ft",
    "tags": [
      "deepseek-r1-distill-qwen-1.5b",
      "q4f16_ft",
      "mlc:jp6"
    ],
    "url": "dusty-nv/DeepSeek-R1-Distill-Qwen-1.5B-q4f16_ft-MLC",
    "created_at": "2025-01-29 03:21:23+00:00",
    "last_modified": "2025-01-29 03:21:48+00:00"
  },
  "deepseek-r1-distill-qwen-1.5b-q4f16_0-mlc-jp6": {
    "title": "DeepSeek R1 Qwen-1.5B \u276f MLC q4f16_0 \u276f JetPack 6.1+",
    "quantization": "q4f16_0",
    "tags": [
      "deepseek-r1-distill-qwen-1.5b",
      "q4f16_0",
      "mlc:jp6"
    ]
  },
  "deepseek-r1-distill-qwen-1.5b-q4f16_1-mlc-jp6": {
    "title": "DeepSeek R1 Qwen-1.5B \u276f MLC q4f16_1 \u276f JetPack 6.1+",
    "quantization": "q4f16_1",
    "tags": [
      "deepseek-r1-distill-qwen-1.5b",
      "q4f16_1",
      "mlc:jp6"
    ],
    "url": "mlc-ai/DeepSeek-R1-Distill-Qwen-1.5B-q4f16_1-MLC",
    "created_at": "2025-01-21 00:21:33+00:00",
    "last_modified": "2025-01-21 07:58:52+00:00"
  },
  "deepseek-r1-distill-qwen-1.5b-q4f32_1-mlc-jp6": {
    "title": "DeepSeek R1 Qwen-1.5B \u276f MLC q4f32_1 \u276f JetPack 6.1+",
    "quantization": "q4f32_1",
    "tags": [
      "deepseek-r1-distill-qwen-1.5b",
      "q4f32_1",
      "mlc:jp6"
    ],
    "url": "mlc-ai/DeepSeek-R1-Distill-Qwen-1.5B-q4f32_1-MLC",
    "created_at": "2025-01-21 00:24:11+00:00",
    "last_modified": "2025-01-21 07:59:21+00:00"
  },
  "deepseek-r1-distill-qwen-1.5b-q4f16_2-mlc-jp6": {
    "title": "DeepSeek R1 Qwen-1.5B \u276f MLC q4f16_2 \u276f JetPack 6.1+",
    "quantization": "q4f16_2",
    "tags": [
      "deepseek-r1-distill-qwen-1.5b",
      "q4f16_2",
      "mlc:jp6"
    ]
  },
  "deepseek-r1-distill-qwen-1.5b-q4f16_awq-mlc-jp6": {
    "title": "DeepSeek R1 Qwen-1.5B \u276f MLC q4f16_awq \u276f JetPack 6.1+",
    "quantization": "q4f16_awq",
    "tags": [
      "deepseek-r1-distill-qwen-1.5b",
      "q4f16_awq",
      "mlc:jp6"
    ]
  },
  "deepseek-r1-distill-qwen-1.5b-e5m2_f16-mlc-jp6": {
    "title": "DeepSeek R1 Qwen-1.5B \u276f MLC e5m2_f16 \u276f JetPack 6.1+",
    "quantization": "e5m2_f16",
    "tags": [
      "deepseek-r1-distill-qwen-1.5b",
      "e5m2_f16",
      "mlc:jp6"
    ]
  },
  "deepseek-r1-distill-qwen-1.5b-e4m3_f16-mlc-jp6": {
    "title": "DeepSeek R1 Qwen-1.5B \u276f MLC e4m3_f16 \u276f JetPack 6.1+",
    "quantization": "e4m3_f16",
    "tags": [
      "deepseek-r1-distill-qwen-1.5b",
      "e4m3_f16",
      "mlc:jp6"
    ]
  },
  "deepseek-r1-distill-qwen-1.5b-e4m3_f16_max-mlc-jp6": {
    "title": "DeepSeek R1 Qwen-1.5B \u276f MLC e4m3_f16_max \u276f JetPack 6.1+",
    "quantization": "e4m3_f16_max",
    "tags": [
      "deepseek-r1-distill-qwen-1.5b",
      "e4m3_f16_max",
      "mlc:jp6"
    ]
  },
  "deepseek-r1-distill-qwen-1.5b-q4_k_m-gguf-jp6": {
    "title": "DeepSeek R1 Qwen-1.5B \u276f llama.cpp q4_k_m \u276f JetPack 6.1+",
    "quantization": "q4_k_m",
    "tags": [
      "deepseek-r1-distill-qwen-1.5b",
      "q4_k_m",
      "llama_cpp:jp6"
    ],
    "url": "bartowski/DeepSeek-R1-Distill-Qwen-1.5B-GGUF/DeepSeek-R1-Distill-Qwen-1.5B-Q4_K_M.gguf",
    "created_at": "2025-01-20 14:52:20+00:00",
    "last_modified": "2025-01-22 15:19:36+00:00"
  },
  "deepseek-r1-distill-qwen-1.5b-q4_k_l-gguf-jp6": {
    "title": "DeepSeek R1 Qwen-1.5B \u276f llama.cpp q4_k_l \u276f JetPack 6.1+",
    "quantization": "q4_k_l",
    "tags": [
      "deepseek-r1-distill-qwen-1.5b",
      "q4_k_l",
      "llama_cpp:jp6"
    ],
    "url": "bartowski/DeepSeek-R1-Distill-Qwen-1.5B-GGUF/DeepSeek-R1-Distill-Qwen-1.5B-Q4_K_L.gguf",
    "created_at": "2025-01-20 14:52:20+00:00",
    "last_modified": "2025-01-22 15:19:36+00:00"
  },
  "deepseek-r1-distill-qwen-1.5b-q5_k_s-gguf-jp6": {
    "title": "DeepSeek R1 Qwen-1.5B \u276f llama.cpp q5_k_s \u276f JetPack 6.1+",
    "quantization": "q5_k_s",
    "tags": [
      "deepseek-r1-distill-qwen-1.5b",
      "q5_k_s",
      "llama_cpp:jp6"
    ],
    "url": "bartowski/DeepSeek-R1-Distill-Qwen-1.5B-GGUF/DeepSeek-R1-Distill-Qwen-1.5B-Q5_K_S.gguf",
    "created_at": "2025-01-20 14:52:20+00:00",
    "last_modified": "2025-01-22 15:19:36+00:00"
  },
  "deepseek-r1-distill-qwen-1.5b-q5_k_m-gguf-jp6": {
    "title": "DeepSeek R1 Qwen-1.5B \u276f llama.cpp q5_k_m \u276f JetPack 6.1+",
    "quantization": "q5_k_m",
    "tags": [
      "deepseek-r1-distill-qwen-1.5b",
      "q5_k_m",
      "llama_cpp:jp6"
    ],
    "url": "bartowski/DeepSeek-R1-Distill-Qwen-1.5B-GGUF/DeepSeek-R1-Distill-Qwen-1.5B-Q5_K_M.gguf",
    "created_at": "2025-01-20 14:52:20+00:00",
    "last_modified": "2025-01-22 15:19:36+00:00"
  },
  "deepseek-r1-distill-qwen-1.5b-q5_k_l-gguf-jp6": {
    "title": "DeepSeek R1 Qwen-1.5B \u276f llama.cpp q5_k_l \u276f JetPack 6.1+",
    "quantization": "q5_k_l",
    "tags": [
      "deepseek-r1-distill-qwen-1.5b",
      "q5_k_l",
      "llama_cpp:jp6"
    ],
    "url": "bartowski/DeepSeek-R1-Distill-Qwen-1.5B-GGUF/DeepSeek-R1-Distill-Qwen-1.5B-Q5_K_L.gguf",
    "created_at": "2025-01-20 14:52:20+00:00",
    "last_modified": "2025-01-22 15:19:36+00:00"
  },
  "deepseek-r1-distill-qwen-1.5b-q6_k-gguf-jp6": {
    "title": "DeepSeek R1 Qwen-1.5B \u276f llama.cpp q6_k \u276f JetPack 6.1+",
    "quantization": "q6_k",
    "tags": [
      "deepseek-r1-distill-qwen-1.5b",
      "q6_k",
      "llama_cpp:jp6"
    ],
    "url": "bartowski/DeepSeek-R1-Distill-Qwen-1.5B-GGUF/DeepSeek-R1-Distill-Qwen-1.5B-Q6_K.gguf",
    "created_at": "2025-01-20 14:52:20+00:00",
    "last_modified": "2025-01-22 15:19:36+00:00"
  },
  "deepseek-r1-distill-qwen-7b": {
    "name": "DeepSeek R1 Qwen-7B",
    "tags": [
      "deepseek-r1-distill",
      "orin"
    ],
    "chat_template": "deepseek_r1_qwen",
    "url": "hf.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
    "links": {
      "deepseek": {
        "name": "DeepSeek",
        "url": "https://www.deepseek.com/"
      },
      "hf": {
        "name": "Hugging Face",
        "color": "yellow",
        "url": "hf.co/deepseek-ai/DeepSeek-R1-Distill-Llama-70B"
      }
    },
    "created_at": "2025-01-20 09:16:14+00:00",
    "last_modified": "2025-01-26 09:15:35+00:00"
  },
  "deepseek-r1-distill-qwen-7b-q4f16_ft-mlc-jp6": {
    "title": "DeepSeek R1 Qwen-7B \u276f MLC q4f16_ft \u276f JetPack 6.1+",
    "quantization": "q4f16_ft",
    "tags": [
      "deepseek-r1-distill-qwen-7b",
      "q4f16_ft",
      "mlc:jp6"
    ],
    "url": "dusty-nv/DeepSeek-R1-Distill-Qwen-7B-q4f16_ft-MLC",
    "created_at": "2025-01-29 03:00:28+00:00",
    "last_modified": "2025-01-29 03:02:04+00:00"
  },
  "deepseek-r1-distill-qwen-7b-q4f16_0-mlc-jp6": {
    "title": "DeepSeek R1 Qwen-7B \u276f MLC q4f16_0 \u276f JetPack 6.1+",
    "quantization": "q4f16_0",
    "tags": [
      "deepseek-r1-distill-qwen-7b",
      "q4f16_0",
      "mlc:jp6"
    ]
  },
  "deepseek-r1-distill-qwen-7b-q4f16_1-mlc-jp6": {
    "title": "DeepSeek R1 Qwen-7B \u276f MLC q4f16_1 \u276f JetPack 6.1+",
    "quantization": "q4f16_1",
    "tags": [
      "deepseek-r1-distill-qwen-7b",
      "q4f16_1",
      "mlc:jp6"
    ],
    "url": "mlc-ai/DeepSeek-R1-Distill-Qwen-7B-q4f16_1-MLC",
    "created_at": "2025-01-21 00:28:25+00:00",
    "last_modified": "2025-01-21 07:59:02+00:00"
  },
  "deepseek-r1-distill-qwen-7b-q4f32_1-mlc-jp6": {
    "title": "DeepSeek R1 Qwen-7B \u276f MLC q4f32_1 \u276f JetPack 6.1+",
    "quantization": "q4f32_1",
    "tags": [
      "deepseek-r1-distill-qwen-7b",
      "q4f32_1",
      "mlc:jp6"
    ],
    "url": "mlc-ai/DeepSeek-R1-Distill-Qwen-7B-q4f32_1-MLC",
    "created_at": "2025-01-21 00:34:45+00:00",
    "last_modified": "2025-01-21 07:59:36+00:00"
  },
  "deepseek-r1-distill-qwen-7b-q4f16_2-mlc-jp6": {
    "title": "DeepSeek R1 Qwen-7B \u276f MLC q4f16_2 \u276f JetPack 6.1+",
    "quantization": "q4f16_2",
    "tags": [
      "deepseek-r1-distill-qwen-7b",
      "q4f16_2",
      "mlc:jp6"
    ]
  },
  "deepseek-r1-distill-qwen-7b-q4f16_awq-mlc-jp6": {
    "title": "DeepSeek R1 Qwen-7B \u276f MLC q4f16_awq \u276f JetPack 6.1+",
    "quantization": "q4f16_awq",
    "tags": [
      "deepseek-r1-distill-qwen-7b",
      "q4f16_awq",
      "mlc:jp6"
    ]
  },
  "deepseek-r1-distill-qwen-7b-e5m2_f16-mlc-jp6": {
    "title": "DeepSeek R1 Qwen-7B \u276f MLC e5m2_f16 \u276f JetPack 6.1+",
    "quantization": "e5m2_f16",
    "tags": [
      "deepseek-r1-distill-qwen-7b",
      "e5m2_f16",
      "mlc:jp6"
    ]
  },
  "deepseek-r1-distill-qwen-7b-e4m3_f16-mlc-jp6": {
    "title": "DeepSeek R1 Qwen-7B \u276f MLC e4m3_f16 \u276f JetPack 6.1+",
    "quantization": "e4m3_f16",
    "tags": [
      "deepseek-r1-distill-qwen-7b",
      "e4m3_f16",
      "mlc:jp6"
    ]
  },
  "deepseek-r1-distill-qwen-7b-e4m3_f16_max-mlc-jp6": {
    "title": "DeepSeek R1 Qwen-7B \u276f MLC e4m3_f16_max \u276f JetPack 6.1+",
    "quantization": "e4m3_f16_max",
    "tags": [
      "deepseek-r1-distill-qwen-7b",
      "e4m3_f16_max",
      "mlc:jp6"
    ]
  },
  "deepseek-r1-distill-qwen-7b-q4_k_m-gguf-jp6": {
    "title": "DeepSeek R1 Qwen-7B \u276f llama.cpp q4_k_m \u276f JetPack 6.1+",
    "quantization": "q4_k_m",
    "tags": [
      "deepseek-r1-distill-qwen-7b",
      "q4_k_m",
      "llama_cpp:jp6"
    ],
    "url": "bartowski/DeepSeek-R1-Distill-Qwen-7B-GGUF/DeepSeek-R1-Distill-Qwen-7B-Q4_K_M.gguf",
    "created_at": "2025-01-20 14:53:04+00:00",
    "last_modified": "2025-01-22 15:19:22+00:00"
  },
  "deepseek-r1-distill-qwen-7b-q4_k_l-gguf-jp6": {
    "title": "DeepSeek R1 Qwen-7B \u276f llama.cpp q4_k_l \u276f JetPack 6.1+",
    "quantization": "q4_k_l",
    "tags": [
      "deepseek-r1-distill-qwen-7b",
      "q4_k_l",
      "llama_cpp:jp6"
    ],
    "url": "bartowski/DeepSeek-R1-Distill-Qwen-7B-GGUF/DeepSeek-R1-Distill-Qwen-7B-Q4_K_L.gguf",
    "created_at": "2025-01-20 14:53:04+00:00",
    "last_modified": "2025-01-22 15:19:22+00:00"
  },
  "deepseek-r1-distill-qwen-7b-q5_k_s-gguf-jp6": {
    "title": "DeepSeek R1 Qwen-7B \u276f llama.cpp q5_k_s \u276f JetPack 6.1+",
    "quantization": "q5_k_s",
    "tags": [
      "deepseek-r1-distill-qwen-7b",
      "q5_k_s",
      "llama_cpp:jp6"
    ],
    "url": "bartowski/DeepSeek-R1-Distill-Qwen-7B-GGUF/DeepSeek-R1-Distill-Qwen-7B-Q5_K_S.gguf",
    "created_at": "2025-01-20 14:53:04+00:00",
    "last_modified": "2025-01-22 15:19:22+00:00"
  },
  "deepseek-r1-distill-qwen-7b-q5_k_m-gguf-jp6": {
    "title": "DeepSeek R1 Qwen-7B \u276f llama.cpp q5_k_m \u276f JetPack 6.1+",
    "quantization": "q5_k_m",
    "tags": [
      "deepseek-r1-distill-qwen-7b",
      "q5_k_m",
      "llama_cpp:jp6"
    ],
    "url": "bartowski/DeepSeek-R1-Distill-Qwen-7B-GGUF/DeepSeek-R1-Distill-Qwen-7B-Q5_K_M.gguf",
    "created_at": "2025-01-20 14:53:04+00:00",
    "last_modified": "2025-01-22 15:19:22+00:00"
  },
  "deepseek-r1-distill-qwen-7b-q5_k_l-gguf-jp6": {
    "title": "DeepSeek R1 Qwen-7B \u276f llama.cpp q5_k_l \u276f JetPack 6.1+",
    "quantization": "q5_k_l",
    "tags": [
      "deepseek-r1-distill-qwen-7b",
      "q5_k_l",
      "llama_cpp:jp6"
    ],
    "url": "bartowski/DeepSeek-R1-Distill-Qwen-7B-GGUF/DeepSeek-R1-Distill-Qwen-7B-Q5_K_L.gguf",
    "created_at": "2025-01-20 14:53:04+00:00",
    "last_modified": "2025-01-22 15:19:22+00:00"
  },
  "deepseek-r1-distill-qwen-7b-q6_k-gguf-jp6": {
    "title": "DeepSeek R1 Qwen-7B \u276f llama.cpp q6_k \u276f JetPack 6.1+",
    "quantization": "q6_k",
    "tags": [
      "deepseek-r1-distill-qwen-7b",
      "q6_k",
      "llama_cpp:jp6"
    ],
    "url": "bartowski/DeepSeek-R1-Distill-Qwen-7B-GGUF/DeepSeek-R1-Distill-Qwen-7B-Q6_K.gguf",
    "created_at": "2025-01-20 14:53:04+00:00",
    "last_modified": "2025-01-22 15:19:22+00:00"
  },
  "deepseek-r1-distill-llama-8b": {
    "name": "DeepSeek R1 Llama-8B",
    "tags": [
      "deepseek-r1-distill",
      "orin"
    ],
    "chat_template": "deepseek_r1_llama",
    "url": "hf.co/deepseek-ai/DeepSeek-R1-Distill-Llama-8B",
    "links": {
      "deepseek": {
        "name": "DeepSeek",
        "url": "https://www.deepseek.com/"
      },
      "hf": {
        "name": "Hugging Face",
        "color": "yellow",
        "url": "hf.co/deepseek-ai/DeepSeek-R1-Distill-Llama-70B"
      }
    },
    "created_at": "2025-01-20 09:09:42+00:00",
    "last_modified": "2025-01-26 09:15:24+00:00"
  },
  "deepseek-r1-distill-llama-8b-q4f16_ft-mlc-jp6": {
    "title": "DeepSeek R1 Llama-8B \u276f MLC q4f16_ft \u276f JetPack 6.1+",
    "quantization": "q4f16_ft",
    "tags": [
      "deepseek-r1-distill-llama-8b",
      "q4f16_ft",
      "mlc:jp6"
    ],
    "url": "dusty-nv/DeepSeek-R1-Distill-Llama-8B-q4f16_ft-MLC",
    "created_at": "2025-01-28 23:12:42+00:00",
    "last_modified": "2025-01-29 02:42:40+00:00"
  },
  "deepseek-r1-distill-llama-8b-q4f16_0-mlc-jp6": {
    "title": "DeepSeek R1 Llama-8B \u276f MLC q4f16_0 \u276f JetPack 6.1+",
    "quantization": "q4f16_0",
    "tags": [
      "deepseek-r1-distill-llama-8b",
      "q4f16_0",
      "mlc:jp6"
    ]
  },
  "deepseek-r1-distill-llama-8b-q4f16_1-mlc-jp6": {
    "title": "DeepSeek R1 Llama-8B \u276f MLC q4f16_1 \u276f JetPack 6.1+",
    "quantization": "q4f16_1",
    "tags": [
      "deepseek-r1-distill-llama-8b",
      "q4f16_1",
      "mlc:jp6"
    ],
    "url": "mlc-ai/DeepSeek-R1-Distill-Llama-8B-q4f16_1-MLC",
    "created_at": "2025-01-21 01:49:30+00:00",
    "last_modified": "2025-01-21 08:02:26+00:00"
  },
  "deepseek-r1-distill-llama-8b-q4f32_1-mlc-jp6": {
    "title": "DeepSeek R1 Llama-8B \u276f MLC q4f32_1 \u276f JetPack 6.1+",
    "quantization": "q4f32_1",
    "tags": [
      "deepseek-r1-distill-llama-8b",
      "q4f32_1",
      "mlc:jp6"
    ],
    "url": "mlc-ai/DeepSeek-R1-Distill-Llama-8B-q4f32_1-MLC",
    "created_at": "2025-01-21 01:56:47+00:00",
    "last_modified": "2025-01-21 08:02:56+00:00"
  },
  "deepseek-r1-distill-llama-8b-q4f16_2-mlc-jp6": {
    "title": "DeepSeek R1 Llama-8B \u276f MLC q4f16_2 \u276f JetPack 6.1+",
    "quantization": "q4f16_2",
    "tags": [
      "deepseek-r1-distill-llama-8b",
      "q4f16_2",
      "mlc:jp6"
    ]
  },
  "deepseek-r1-distill-llama-8b-q4f16_awq-mlc-jp6": {
    "title": "DeepSeek R1 Llama-8B \u276f MLC q4f16_awq \u276f JetPack 6.1+",
    "quantization": "q4f16_awq",
    "tags": [
      "deepseek-r1-distill-llama-8b",
      "q4f16_awq",
      "mlc:jp6"
    ]
  },
  "deepseek-r1-distill-llama-8b-e5m2_f16-mlc-jp6": {
    "title": "DeepSeek R1 Llama-8B \u276f MLC e5m2_f16 \u276f JetPack 6.1+",
    "quantization": "e5m2_f16",
    "tags": [
      "deepseek-r1-distill-llama-8b",
      "e5m2_f16",
      "mlc:jp6"
    ]
  },
  "deepseek-r1-distill-llama-8b-e4m3_f16-mlc-jp6": {
    "title": "DeepSeek R1 Llama-8B \u276f MLC e4m3_f16 \u276f JetPack 6.1+",
    "quantization": "e4m3_f16",
    "tags": [
      "deepseek-r1-distill-llama-8b",
      "e4m3_f16",
      "mlc:jp6"
    ]
  },
  "deepseek-r1-distill-llama-8b-e4m3_f16_max-mlc-jp6": {
    "title": "DeepSeek R1 Llama-8B \u276f MLC e4m3_f16_max \u276f JetPack 6.1+",
    "quantization": "e4m3_f16_max",
    "tags": [
      "deepseek-r1-distill-llama-8b",
      "e4m3_f16_max",
      "mlc:jp6"
    ]
  },
  "deepseek-r1-distill-llama-8b-q4_k_m-gguf-jp6": {
    "title": "DeepSeek R1 Llama-8B \u276f llama.cpp q4_k_m \u276f JetPack 6.1+",
    "quantization": "q4_k_m",
    "tags": [
      "deepseek-r1-distill-llama-8b",
      "q4_k_m",
      "llama_cpp:jp6"
    ],
    "url": "bartowski/DeepSeek-R1-Distill-Llama-8B-GGUF/DeepSeek-R1-Distill-Llama-8B-Q4_K_M.gguf",
    "created_at": "2025-01-20 14:52:51+00:00",
    "last_modified": "2025-01-22 15:19:31+00:00"
  },
  "deepseek-r1-distill-llama-8b-q4_k_l-gguf-jp6": {
    "title": "DeepSeek R1 Llama-8B \u276f llama.cpp q4_k_l \u276f JetPack 6.1+",
    "quantization": "q4_k_l",
    "tags": [
      "deepseek-r1-distill-llama-8b",
      "q4_k_l",
      "llama_cpp:jp6"
    ],
    "url": "bartowski/DeepSeek-R1-Distill-Llama-8B-GGUF/DeepSeek-R1-Distill-Llama-8B-Q4_K_L.gguf",
    "created_at": "2025-01-20 14:52:51+00:00",
    "last_modified": "2025-01-22 15:19:31+00:00"
  },
  "deepseek-r1-distill-llama-8b-q5_k_s-gguf-jp6": {
    "title": "DeepSeek R1 Llama-8B \u276f llama.cpp q5_k_s \u276f JetPack 6.1+",
    "quantization": "q5_k_s",
    "tags": [
      "deepseek-r1-distill-llama-8b",
      "q5_k_s",
      "llama_cpp:jp6"
    ],
    "url": "bartowski/DeepSeek-R1-Distill-Llama-8B-GGUF/DeepSeek-R1-Distill-Llama-8B-Q5_K_S.gguf",
    "created_at": "2025-01-20 14:52:51+00:00",
    "last_modified": "2025-01-22 15:19:31+00:00"
  },
  "deepseek-r1-distill-llama-8b-q5_k_m-gguf-jp6": {
    "title": "DeepSeek R1 Llama-8B \u276f llama.cpp q5_k_m \u276f JetPack 6.1+",
    "quantization": "q5_k_m",
    "tags": [
      "deepseek-r1-distill-llama-8b",
      "q5_k_m",
      "llama_cpp:jp6"
    ],
    "url": "bartowski/DeepSeek-R1-Distill-Llama-8B-GGUF/DeepSeek-R1-Distill-Llama-8B-Q5_K_M.gguf",
    "created_at": "2025-01-20 14:52:51+00:00",
    "last_modified": "2025-01-22 15:19:31+00:00"
  },
  "deepseek-r1-distill-llama-8b-q5_k_l-gguf-jp6": {
    "title": "DeepSeek R1 Llama-8B \u276f llama.cpp q5_k_l \u276f JetPack 6.1+",
    "quantization": "q5_k_l",
    "tags": [
      "deepseek-r1-distill-llama-8b",
      "q5_k_l",
      "llama_cpp:jp6"
    ],
    "url": "bartowski/DeepSeek-R1-Distill-Llama-8B-GGUF/DeepSeek-R1-Distill-Llama-8B-Q5_K_L.gguf",
    "created_at": "2025-01-20 14:52:51+00:00",
    "last_modified": "2025-01-22 15:19:31+00:00"
  },
  "deepseek-r1-distill-llama-8b-q6_k-gguf-jp6": {
    "title": "DeepSeek R1 Llama-8B \u276f llama.cpp q6_k \u276f JetPack 6.1+",
    "quantization": "q6_k",
    "tags": [
      "deepseek-r1-distill-llama-8b",
      "q6_k",
      "llama_cpp:jp6"
    ],
    "url": "bartowski/DeepSeek-R1-Distill-Llama-8B-GGUF/DeepSeek-R1-Distill-Llama-8B-Q6_K.gguf",
    "created_at": "2025-01-20 14:52:51+00:00",
    "last_modified": "2025-01-22 15:19:31+00:00"
  },
  "deepseek-r1-distill-qwen-32b": {
    "name": "DeepSeek R1 Qwen-32B",
    "tags": [
      "deepseek-r1-distill",
      "agx-orin"
    ],
    "chat_template": "deepseek_r1_qwen",
    "url": "hf.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
    "links": {
      "deepseek": {
        "name": "DeepSeek",
        "url": "https://www.deepseek.com/"
      },
      "hf": {
        "name": "Hugging Face",
        "color": "yellow",
        "url": "hf.co/deepseek-ai/DeepSeek-R1-Distill-Llama-70B"
      }
    },
    "created_at": "2025-01-20 09:19:00+00:00",
    "last_modified": "2025-01-26 09:15:32+00:00"
  },
  "deepseek-r1-distill-qwen-32b-q4f16_ft-mlc-jp6": {
    "title": "DeepSeek R1 Qwen-32B \u276f MLC q4f16_ft \u276f JetPack 6.1+",
    "quantization": "q4f16_ft",
    "tags": [
      "deepseek-r1-distill-qwen-32b",
      "q4f16_ft",
      "mlc:jp6"
    ]
  },
  "deepseek-r1-distill-qwen-32b-q4f16_0-mlc-jp6": {
    "title": "DeepSeek R1 Qwen-32B \u276f MLC q4f16_0 \u276f JetPack 6.1+",
    "quantization": "q4f16_0",
    "tags": [
      "deepseek-r1-distill-qwen-32b",
      "q4f16_0",
      "mlc:jp6"
    ]
  },
  "deepseek-r1-distill-qwen-32b-q4f16_1-mlc-jp6": {
    "title": "DeepSeek R1 Qwen-32B \u276f MLC q4f16_1 \u276f JetPack 6.1+",
    "quantization": "q4f16_1",
    "tags": [
      "deepseek-r1-distill-qwen-32b",
      "q4f16_1",
      "mlc:jp6"
    ],
    "url": "mlc-ai/DeepSeek-R1-Distill-Qwen-32B-q4f16_1-MLC",
    "created_at": "2025-01-21 01:07:21+00:00",
    "last_modified": "2025-01-21 07:59:58+00:00"
  },
  "deepseek-r1-distill-qwen-32b-q4f32_1-mlc-jp6": {
    "title": "DeepSeek R1 Qwen-32B \u276f MLC q4f32_1 \u276f JetPack 6.1+",
    "quantization": "q4f32_1",
    "tags": [
      "deepseek-r1-distill-qwen-32b",
      "q4f32_1",
      "mlc:jp6"
    ],
    "url": "mlc-ai/DeepSeek-R1-Distill-Qwen-32B-q4f32_1-MLC",
    "created_at": "2025-01-21 01:37:18+00:00",
    "last_modified": "2025-01-21 08:00:15+00:00"
  },
  "deepseek-r1-distill-qwen-32b-q4f16_2-mlc-jp6": {
    "title": "DeepSeek R1 Qwen-32B \u276f MLC q4f16_2 \u276f JetPack 6.1+",
    "quantization": "q4f16_2",
    "tags": [
      "deepseek-r1-distill-qwen-32b",
      "q4f16_2",
      "mlc:jp6"
    ]
  },
  "deepseek-r1-distill-qwen-32b-q4f16_awq-mlc-jp6": {
    "title": "DeepSeek R1 Qwen-32B \u276f MLC q4f16_awq \u276f JetPack 6.1+",
    "quantization": "q4f16_awq",
    "tags": [
      "deepseek-r1-distill-qwen-32b",
      "q4f16_awq",
      "mlc:jp6"
    ]
  },
  "deepseek-r1-distill-qwen-32b-e5m2_f16-mlc-jp6": {
    "title": "DeepSeek R1 Qwen-32B \u276f MLC e5m2_f16 \u276f JetPack 6.1+",
    "quantization": "e5m2_f16",
    "tags": [
      "deepseek-r1-distill-qwen-32b",
      "e5m2_f16",
      "mlc:jp6"
    ]
  },
  "deepseek-r1-distill-qwen-32b-e4m3_f16-mlc-jp6": {
    "title": "DeepSeek R1 Qwen-32B \u276f MLC e4m3_f16 \u276f JetPack 6.1+",
    "quantization": "e4m3_f16",
    "tags": [
      "deepseek-r1-distill-qwen-32b",
      "e4m3_f16",
      "mlc:jp6"
    ]
  },
  "deepseek-r1-distill-qwen-32b-e4m3_f16_max-mlc-jp6": {
    "title": "DeepSeek R1 Qwen-32B \u276f MLC e4m3_f16_max \u276f JetPack 6.1+",
    "quantization": "e4m3_f16_max",
    "tags": [
      "deepseek-r1-distill-qwen-32b",
      "e4m3_f16_max",
      "mlc:jp6"
    ]
  },
  "deepseek-r1-distill-qwen-32b-q4_k_m-gguf-jp6": {
    "title": "DeepSeek R1 Qwen-32B \u276f llama.cpp q4_k_m \u276f JetPack 6.1+",
    "quantization": "q4_k_m",
    "tags": [
      "deepseek-r1-distill-qwen-32b",
      "q4_k_m",
      "llama_cpp:jp6"
    ],
    "url": "bartowski/DeepSeek-R1-Distill-Qwen-32B-GGUF/DeepSeek-R1-Distill-Qwen-32B-Q4_K_M.gguf",
    "created_at": "2025-01-20 14:02:00+00:00",
    "last_modified": "2025-01-22 15:19:08+00:00"
  },
  "deepseek-r1-distill-qwen-32b-q4_k_l-gguf-jp6": {
    "title": "DeepSeek R1 Qwen-32B \u276f llama.cpp q4_k_l \u276f JetPack 6.1+",
    "quantization": "q4_k_l",
    "tags": [
      "deepseek-r1-distill-qwen-32b",
      "q4_k_l",
      "llama_cpp:jp6"
    ],
    "url": "bartowski/DeepSeek-R1-Distill-Qwen-32B-GGUF/DeepSeek-R1-Distill-Qwen-32B-Q4_K_L.gguf",
    "created_at": "2025-01-20 14:02:00+00:00",
    "last_modified": "2025-01-22 15:19:08+00:00"
  },
  "deepseek-r1-distill-qwen-32b-q5_k_s-gguf-jp6": {
    "title": "DeepSeek R1 Qwen-32B \u276f llama.cpp q5_k_s \u276f JetPack 6.1+",
    "quantization": "q5_k_s",
    "tags": [
      "deepseek-r1-distill-qwen-32b",
      "q5_k_s",
      "llama_cpp:jp6"
    ],
    "url": "bartowski/DeepSeek-R1-Distill-Qwen-32B-GGUF/DeepSeek-R1-Distill-Qwen-32B-Q5_K_S.gguf",
    "created_at": "2025-01-20 14:02:00+00:00",
    "last_modified": "2025-01-22 15:19:08+00:00"
  },
  "deepseek-r1-distill-qwen-32b-q5_k_m-gguf-jp6": {
    "title": "DeepSeek R1 Qwen-32B \u276f llama.cpp q5_k_m \u276f JetPack 6.1+",
    "quantization": "q5_k_m",
    "tags": [
      "deepseek-r1-distill-qwen-32b",
      "q5_k_m",
      "llama_cpp:jp6"
    ],
    "url": "bartowski/DeepSeek-R1-Distill-Qwen-32B-GGUF/DeepSeek-R1-Distill-Qwen-32B-Q5_K_M.gguf",
    "created_at": "2025-01-20 14:02:00+00:00",
    "last_modified": "2025-01-22 15:19:08+00:00"
  },
  "deepseek-r1-distill-qwen-32b-q5_k_l-gguf-jp6": {
    "title": "DeepSeek R1 Qwen-32B \u276f llama.cpp q5_k_l \u276f JetPack 6.1+",
    "quantization": "q5_k_l",
    "tags": [
      "deepseek-r1-distill-qwen-32b",
      "q5_k_l",
      "llama_cpp:jp6"
    ],
    "url": "bartowski/DeepSeek-R1-Distill-Qwen-32B-GGUF/DeepSeek-R1-Distill-Qwen-32B-Q5_K_L.gguf",
    "created_at": "2025-01-20 14:02:00+00:00",
    "last_modified": "2025-01-22 15:19:08+00:00"
  },
  "deepseek-r1-distill-qwen-32b-q6_k-gguf-jp6": {
    "title": "DeepSeek R1 Qwen-32B \u276f llama.cpp q6_k \u276f JetPack 6.1+",
    "quantization": "q6_k",
    "tags": [
      "deepseek-r1-distill-qwen-32b",
      "q6_k",
      "llama_cpp:jp6"
    ],
    "url": "bartowski/DeepSeek-R1-Distill-Qwen-32B-GGUF/DeepSeek-R1-Distill-Qwen-32B-Q6_K.gguf",
    "created_at": "2025-01-20 14:02:00+00:00",
    "last_modified": "2025-01-22 15:19:08+00:00"
  },
  "deepseek-r1-distill-llama-70b": {
    "name": "DeepSeek R1 Llama-70B",
    "tags": [
      "deepseek-r1-distill",
      "agx-orin"
    ],
    "chat_template": "deepseek_r1_llama",
    "url": "hf.co/deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
    "links": {
      "deepseek": {
        "name": "DeepSeek",
        "url": "https://www.deepseek.com/"
      },
      "hf": {
        "name": "Hugging Face",
        "color": "yellow",
        "url": "hf.co/deepseek-ai/DeepSeek-R1-Distill-Llama-70B"
      }
    },
    "created_at": "2025-01-20 09:13:33+00:00",
    "last_modified": "2025-01-26 09:15:21+00:00"
  },
  "deepseek-r1-distill-llama-70b-q4f16_ft-mlc-jp6": {
    "title": "DeepSeek R1 Llama-70B \u276f MLC q4f16_ft \u276f JetPack 6.1+",
    "quantization": "q4f16_ft",
    "tags": [
      "deepseek-r1-distill-llama-70b",
      "q4f16_ft",
      "mlc:jp6"
    ]
  },
  "deepseek-r1-distill-llama-70b-q4f16_0-mlc-jp6": {
    "title": "DeepSeek R1 Llama-70B \u276f MLC q4f16_0 \u276f JetPack 6.1+",
    "quantization": "q4f16_0",
    "tags": [
      "deepseek-r1-distill-llama-70b",
      "q4f16_0",
      "mlc:jp6"
    ]
  },
  "deepseek-r1-distill-llama-70b-q4f16_1-mlc-jp6": {
    "title": "DeepSeek R1 Llama-70B \u276f MLC q4f16_1 \u276f JetPack 6.1+",
    "quantization": "q4f16_1",
    "tags": [
      "deepseek-r1-distill-llama-70b",
      "q4f16_1",
      "mlc:jp6"
    ],
    "url": "mlc-ai/DeepSeek-R1-Distill-Llama-70B-q4f16_1-MLC",
    "created_at": "2025-01-21 02:19:24+00:00",
    "last_modified": "2025-01-21 08:03:05+00:00"
  },
  "deepseek-r1-distill-llama-70b-q4f32_1-mlc-jp6": {
    "title": "DeepSeek R1 Llama-70B \u276f MLC q4f32_1 \u276f JetPack 6.1+",
    "quantization": "q4f32_1",
    "tags": [
      "deepseek-r1-distill-llama-70b",
      "q4f32_1",
      "mlc:jp6"
    ],
    "url": "mlc-ai/DeepSeek-R1-Distill-Llama-70B-q4f32_1-MLC",
    "created_at": "2025-01-21 03:21:00+00:00",
    "last_modified": "2025-01-21 08:03:13+00:00"
  },
  "deepseek-r1-distill-llama-70b-q4f16_2-mlc-jp6": {
    "title": "DeepSeek R1 Llama-70B \u276f MLC q4f16_2 \u276f JetPack 6.1+",
    "quantization": "q4f16_2",
    "tags": [
      "deepseek-r1-distill-llama-70b",
      "q4f16_2",
      "mlc:jp6"
    ]
  },
  "deepseek-r1-distill-llama-70b-q4f16_awq-mlc-jp6": {
    "title": "DeepSeek R1 Llama-70B \u276f MLC q4f16_awq \u276f JetPack 6.1+",
    "quantization": "q4f16_awq",
    "tags": [
      "deepseek-r1-distill-llama-70b",
      "q4f16_awq",
      "mlc:jp6"
    ]
  },
  "deepseek-r1-distill-llama-70b-e5m2_f16-mlc-jp6": {
    "title": "DeepSeek R1 Llama-70B \u276f MLC e5m2_f16 \u276f JetPack 6.1+",
    "quantization": "e5m2_f16",
    "tags": [
      "deepseek-r1-distill-llama-70b",
      "e5m2_f16",
      "mlc:jp6"
    ]
  },
  "deepseek-r1-distill-llama-70b-e4m3_f16-mlc-jp6": {
    "title": "DeepSeek R1 Llama-70B \u276f MLC e4m3_f16 \u276f JetPack 6.1+",
    "quantization": "e4m3_f16",
    "tags": [
      "deepseek-r1-distill-llama-70b",
      "e4m3_f16",
      "mlc:jp6"
    ]
  },
  "deepseek-r1-distill-llama-70b-e4m3_f16_max-mlc-jp6": {
    "title": "DeepSeek R1 Llama-70B \u276f MLC e4m3_f16_max \u276f JetPack 6.1+",
    "quantization": "e4m3_f16_max",
    "tags": [
      "deepseek-r1-distill-llama-70b",
      "e4m3_f16_max",
      "mlc:jp6"
    ]
  },
  "deepseek-r1-distill-llama-70b-q4_k_m-gguf-jp6": {
    "title": "DeepSeek R1 Llama-70B \u276f llama.cpp q4_k_m \u276f JetPack 6.1+",
    "quantization": "q4_k_m",
    "tags": [
      "deepseek-r1-distill-llama-70b",
      "q4_k_m",
      "llama_cpp:jp6"
    ],
    "url": "bartowski/DeepSeek-R1-Distill-Llama-70B-GGUF/DeepSeek-R1-Distill-Llama-70B-Q4_K_M.gguf",
    "created_at": "2025-01-20 17:08:16+00:00",
    "last_modified": "2025-01-22 15:19:01+00:00"
  },
  "deepseek-r1-distill-llama-70b-q4_k_l-gguf-jp6": {
    "title": "DeepSeek R1 Llama-70B \u276f llama.cpp q4_k_l \u276f JetPack 6.1+",
    "quantization": "q4_k_l",
    "tags": [
      "deepseek-r1-distill-llama-70b",
      "q4_k_l",
      "llama_cpp:jp6"
    ]
  },
  "deepseek-r1-distill-llama-70b-q5_k_s-gguf-jp6": {
    "title": "DeepSeek R1 Llama-70B \u276f llama.cpp q5_k_s \u276f JetPack 6.1+",
    "quantization": "q5_k_s",
    "tags": [
      "deepseek-r1-distill-llama-70b",
      "q5_k_s",
      "llama_cpp:jp6"
    ],
    "url": "bartowski/DeepSeek-R1-Distill-Llama-70B-GGUF/DeepSeek-R1-Distill-Llama-70B-Q5_K_S.gguf",
    "created_at": "2025-01-20 17:08:16+00:00",
    "last_modified": "2025-01-22 15:19:01+00:00"
  },
  "deepseek-r1-distill-llama-70b-q5_k_m-gguf-jp6": {
    "title": "DeepSeek R1 Llama-70B \u276f llama.cpp q5_k_m \u276f JetPack 6.1+",
    "quantization": "q5_k_m",
    "tags": [
      "deepseek-r1-distill-llama-70b",
      "q5_k_m",
      "llama_cpp:jp6"
    ]
  },
  "deepseek-r1-distill-llama-70b-q5_k_l-gguf-jp6": {
    "title": "DeepSeek R1 Llama-70B \u276f llama.cpp q5_k_l \u276f JetPack 6.1+",
    "quantization": "q5_k_l",
    "tags": [
      "deepseek-r1-distill-llama-70b",
      "q5_k_l",
      "llama_cpp:jp6"
    ]
  },
  "deepseek-r1-distill-llama-70b-q6_k-gguf-jp6": {
    "title": "DeepSeek R1 Llama-70B \u276f llama.cpp q6_k \u276f JetPack 6.1+",
    "quantization": "q6_k",
    "tags": [
      "deepseek-r1-distill-llama-70b",
      "q6_k",
      "llama_cpp:jp6"
    ]
  },
  "qwen-2.5-500m": {
    "name": "Qwen 2.5 0.5B",
    "title": "Qwen 2.5 0.5B",
    "header": "qwen-header",
    "tags": [
      "qwen-2.5",
      "agx-orin",
      "orin-nx",
      "orin-nano"
    ],
    "max_context_len": 4096,
    "prefill_chunk": 4096,
    "links": {
      "meta": {
        "name": "Qwen",
        "url": "https://qwenlm.github.io",
        "color": "blue"
      },
      "hf": {
        "name": "Hugging Face",
        "url": "https://huggingface.co/Qwen/Qwen2.5-0.5B-Instruct",
        "color": "yellow"
      }
    }
  },
  "qwen-2.5-500m-instruct-q4f16_ft-mlc": {
    "name": "qwen/qwen2.5-0.5b-instruct-q4f16_ft",
    "title": "Qwen-2.5-0.5B \u276f MLC q4f16_ft \u276f JetPack 6.1+",
    "url": "hf.co/dusty-nv/Qwen2.5-0.5B-Instruct-q4f16_ft-MLC",
    "quantization": "q4f16_ft",
    "tags": [
      "qwen-2.5-500m",
      "mlc:jp6",
      "agx-orin",
      "orin-nx",
      "orin-nano"
    ]
  },
  "qwen-2.5-500m-instruct-q4f16_1-mlc": {
    "name": "qwen/qwen2.5-0.5b-instruct-q4f16_1",
    "title": "Qwen-2.5-0.5B \u276f MLC q4f16_1 \u276f JetPack 6.1+",
    "url": "hf.co/mlc-ai/Qwen2.5-0.5B-Instruct-q4f16_1-MLC",
    "quantization": "q4f16_1",
    "tags": [
      "qwen-2.5-500m",
      "mlc:jp6",
      "agx-orin",
      "orin-nx",
      "orin-nano"
    ]
  },
  "qwen-2.5-500m-instruct-q4m-gguf": {
    "name": "bartowski/Qwen2.5-0.5B-Instruct-GGUF",
    "title": "Qwen-2.5-0.5B \u276f llama.cpp Q4_K_M \u276f JetPack 6.1+",
    "url": "hf.co/bartowski/Qwen2.5-0.5B-Instruct-GGUF/Qwen2.5-0.5B-Instruct-Q4_K_M.gguf",
    "quantization": "q4_k_m",
    "tokenizer": "pcuenq/Llama-3.2-1B-Instruct-tokenizer",
    "max_context_len": 4096,
    "prefill_chunk": 4096,
    "tags": [
      "qwen-2.5-500m",
      "llama_cpp:jp6",
      "agx-orin",
      "orin-nx",
      "orin-nano"
    ]
  },
  "qwen-2.5-500m-instruct-q5m-gguf": {
    "name": "bartowski/Qwen2.5-0.5B-Instruct-GGUF",
    "title": "Qwen-2.5-0.5B \u276f llama.cpp Q5_K_M \u276f JetPack 6.1+",
    "url": "hf.co/bartowski/Qwen2.5-0.5B-Instruct-GGUF/Qwen2.5-0.5B-Instruct-Q5_K_M.gguf",
    "quantization": "q5_k_m",
    "tokenizer": "pcuenq/Llama-3.2-1B-Instruct-tokenizer",
    "max_context_len": 4096,
    "prefill_chunk": 4096,
    "tags": [
      "qwen-2.5-500m",
      "llama_cpp:jp6",
      "agx-orin",
      "orin-nx",
      "orin-nano"
    ]
  },
  "qwen-2.5-500m-instruct-q6k-gguf": {
    "name": "bartowski/Qwen2.5-0.5B-Instruct-GGUF",
    "title": "Qwen-2.5-0.5B \u276f llama.cpp Q6_K \u276f JetPack 6.1+",
    "url": "hf.co/bartowski/Qwen2.5-0.5B-Instruct-GGUF/Qwen2.5-0.5B-Instruct-Q6_K.gguf",
    "quantization": "q6_k",
    "tokenizer": "pcuenq/Llama-3.2-1B-Instruct-tokenizer",
    "max_context_len": 4096,
    "prefill_chunk": 4096,
    "tags": [
      "qwen-2.5-500m",
      "llama_cpp:jp6",
      "agx-orin",
      "orin-nx",
      "orin-nano"
    ]
  },
  "qwen-2.5-1500m": {
    "name": "Qwen 2.5 1.5B",
    "title": "Qwen 2.5 1.5B",
    "header": "qwen-header",
    "tags": [
      "qwen-2.5",
      "agx-orin",
      "orin-nx",
      "orin-nano"
    ],
    "max_context_len": 4096,
    "prefill_chunk": 4096,
    "links": {
      "meta": {
        "name": "Qwen",
        "url": "https://qwenlm.github.io",
        "color": "blue"
      },
      "hf": {
        "name": "Hugging Face",
        "url": "https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct",
        "color": "yellow"
      }
    }
  },
  "qwen-2.5-1500m-instruct-q4f16_ft-mlc": {
    "name": "qwen/qwen2.5-1.5b-instruct-q4f16_ft",
    "title": "Qwen-2.5-1.5B \u276f MLC q4f16_ft \u276f JetPack 6.1+",
    "url": "hf.co/dusty-nv/Qwen2.5-1.5B-Instruct-q4f16_ft-MLC",
    "quantization": "q4f16_ft",
    "tags": [
      "qwen-2.5-1500m",
      "mlc:jp6",
      "agx-orin",
      "orin-nx",
      "orin-nano"
    ]
  },
  "qwen-2.5-1500m-instruct-q4f16_1-mlc": {
    "name": "qwen/qwen2.5-1.5b-instruct-q4f16_1",
    "title": "Qwen-2.5-1.5B \u276f MLC q4f16_1 \u276f JetPack 6.1+",
    "url": "hf.co/mlc-ai/Qwen2.5-1.5B-Instruct-q4f16_1-MLC",
    "quantization": "q4f16_1",
    "tags": [
      "qwen-2.5-1500m",
      "mlc:jp6",
      "agx-orin",
      "orin-nx",
      "orin-nano"
    ]
  },
  "qwen-2.5-1500m-instruct-q4m-gguf": {
    "name": "bartowski/Qwen2.5-1.5B-Instruct-GGUF",
    "title": "Qwen-2.5-1.5B \u276f llama.cpp Q4_K_M \u276f JetPack 6.1+",
    "url": "hf.co/bartowski/Qwen2.5-1.5B-Instruct-GGUF/Qwen2.5-1.5B-Instruct-Q4_K_M.gguf",
    "quantization": "q4_k_m",
    "tokenizer": "pcuenq/Llama-3.2-1B-Instruct-tokenizer",
    "max_context_len": 4096,
    "prefill_chunk": 4096,
    "tags": [
      "qwen-2.5-1500m",
      "llama_cpp:jp6",
      "agx-orin",
      "orin-nx",
      "orin-nano"
    ]
  },
  "qwen-2.5-1500m-instruct-q5m-gguf": {
    "name": "bartowski/Qwen2.5-1.5B-Instruct-GGUF",
    "title": "Qwen-2.5-1.5B \u276f llama.cpp Q5_K_M \u276f JetPack 6.1+",
    "url": "hf.co/bartowski/Qwen2.5-1.5B-Instruct-GGUF/Qwen2.5-1.5B-Instruct-Q5_K_M.gguf",
    "quantization": "q5_k_m",
    "tokenizer": "pcuenq/Llama-3.2-1B-Instruct-tokenizer",
    "max_context_len": 4096,
    "prefill_chunk": 4096,
    "tags": [
      "qwen-2.5-1500m",
      "llama_cpp:jp6",
      "agx-orin",
      "orin-nx",
      "orin-nano"
    ]
  },
  "qwen-2.5-1500m-instruct-q6k-gguf": {
    "name": "bartowski/Qwen2.5-1.5B-Instruct-GGUF",
    "title": "Qwen-2.5-1.5B \u276f llama.cpp Q6_K \u276f JetPack 6.1+",
    "url": "hf.co/bartowski/Qwen2.5-1.5B-Instruct-GGUF/Qwen2.5-1.5B-Instruct-Q6_K.gguf",
    "quantization": "q6_k",
    "tokenizer": "pcuenq/Llama-3.2-1B-Instruct-tokenizer",
    "max_context_len": 4096,
    "prefill_chunk": 4096,
    "tags": [
      "qwen-2.5-1500m",
      "llama_cpp:jp6",
      "agx-orin",
      "orin-nx",
      "orin-nano"
    ]
  },
  "qwen-2.5": {
    "name": "Qwen 2.5",
    "tags": [
      "llm"
    ]
  },
  "qwen-2.5-7b": {
    "name": "Qwen 2.5 7B",
    "title": "Qwen 2.5 7B",
    "header": "qwen-header",
    "tags": [
      "qwen-2.5",
      "agx-orin",
      "orin-nx",
      "orin-nano"
    ],
    "max_context_len": 2048,
    "prefill_chunk": 1024,
    "links": {
      "meta": {
        "name": "Qwen",
        "url": "https://qwenlm.github.io",
        "color": "blue"
      },
      "hf": {
        "name": "Hugging Face",
        "url": "https://huggingface.co/Qwen/Qwen2.5-7B-Instruct",
        "color": "yellow"
      }
    }
  },
  "qwen-2.5-7b-instruct-q4f16_ft-mlc": {
    "name": "qwen/qwen2.5-1.5b-instruct-q4f16_ft",
    "title": "Qwen-2.5-7B \u276f MLC q4f16_ft \u276f JetPack 6.1+",
    "url": "hf.co/dusty-nv/Qwen2.5-7B-Instruct-q4f16_ft-MLC",
    "quantization": "q4f16_ft",
    "tags": [
      "qwen-2.5-7b",
      "mlc:jp6",
      "agx-orin",
      "orin-nx",
      "orin-nano"
    ]
  },
  "qwen-2.5-7b-instruct-q4f16_1-mlc": {
    "name": "qwen/qwen2.5-1.5b-instruct-q4f16_1",
    "title": "Qwen-2.5-7B \u276f MLC q4f16_1 \u276f JetPack 6.1+",
    "url": "hf.co/mlc-ai/Qwen2.5-7B-Instruct-q4f16_1-MLC",
    "quantization": "q4f16_1",
    "tags": [
      "qwen-2.5-7b",
      "mlc:jp6",
      "agx-orin",
      "orin-nx",
      "orin-nano"
    ]
  },
  "qwen-2.5-7b-instruct-q4m-gguf": {
    "name": "bartowski/Qwen2.5-7B-Instruct-GGUF",
    "title": "Qwen-2.5-7B \u276f llama.cpp Q4_K_M \u276f JetPack 6.1+",
    "url": "hf.co/bartowski/Qwen2.5-7B-Instruct-GGUF/Qwen2.5-7B-Instruct-Q4_K_M.gguf",
    "quantization": "q4_k_m",
    "tokenizer": "pcuenq/Llama-3.2-1B-Instruct-tokenizer",
    "max_context_len": 2048,
    "prefill_chunk": 1024,
    "tags": [
      "qwen-2.5-7b",
      "llama_cpp:jp6",
      "agx-orin",
      "orin-nx",
      "orin-nano"
    ]
  },
  "qwen-2.5-7b-instruct-q5m-gguf": {
    "name": "bartowski/Qwen2.5-7B-Instruct-GGUF",
    "title": "Qwen-2.5-7B \u276f llama.cpp Q5_K_M \u276f JetPack 6.1+",
    "url": "hf.co/bartowski/Qwen2.5-7B-Instruct-GGUF/Qwen2.5-7B-Instruct-Q5_K_M.gguf",
    "quantization": "q5_k_m",
    "tokenizer": "pcuenq/Llama-3.2-1B-Instruct-tokenizer",
    "max_context_len": 2048,
    "prefill_chunk": 1024,
    "tags": [
      "qwen-2.5-7b",
      "llama_cpp:jp6",
      "agx-orin",
      "orin-nx",
      "orin-nano"
    ]
  },
  "qwen-2.5-7b-instruct-q6k-gguf": {
    "name": "bartowski/Qwen2.5-7B-Instruct-GGUF",
    "title": "Qwen-2.5-7B \u276f llama.cpp Q6_K \u276f JetPack 6.1+",
    "url": "hf.co/bartowski/Qwen2.5-7B-Instruct-GGUF/Qwen2.5-7B-Instruct-Q6_K.gguf",
    "quantization": "q6_k",
    "tokenizer": "pcuenq/Llama-3.2-1B-Instruct-tokenizer",
    "max_context_len": 2048,
    "prefill_chunk": 1024,
    "tags": [
      "qwen-2.5-7b",
      "llama_cpp:jp6",
      "agx-orin",
      "orin-nx",
      "orin-nano"
    ]
  },
  "gemma-2-2b": {
    "name": "Gemma 2 2B",
    "title": "Gemma 2 2B",
    "header": "gemma-header",
    "tags": [
      "gemma-2",
      "agx-orin",
      "orin-nx",
      "orin-nano"
    ],
    "max_context_len": {
      "placeholder": 8192
    },
    "prefill_chunk": {
      "placeholder": 8192
    },
    "links": {
      "meta": {
        "name": "Google",
        "url": "https://ai.google.dev/gemma",
        "color": "blue"
      },
      "hf": {
        "name": "Hugging Face",
        "url": "https://huggingface.co/google/gemma-2-2b-it",
        "color": "yellow"
      }
    }
  },
  "gemma-2-2b-it-q4f16_1-mlc": {
    "name": "google/gemma-2-2b-it-q4f16_1",
    "title": "Llama-3.2-1B \u276f MLC q4f16_1 \u276f JetPack 6.1+",
    "url": "hf.co/mlc-ai/gemma-2-2b-it-q4f16_1-MLC",
    "quantization": "q4f16_1",
    "tags": [
      "gemma-2-2b",
      "mlc:jp6",
      "agx-orin",
      "orin-nx",
      "orin-nano"
    ]
  },
  "gemma-2-2b-it-q4m-gguf": {
    "name": "bartowski/gemma-2-2b-it-GGUF",
    "title": "Llama-3.2-1B \u276f llama.cpp Q4_K_M \u276f JetPack 6.1+",
    "url": "hf.co/bartowski/gemma-2-2b-it-GGUF/gemma-2-2b-it-Q4_K_M.gguf",
    "quantization": "q4_k_m",
    "tokenizer": "pcuenq/Llama-3.2-1B-Instruct-tokenizer",
    "max_context_len": 8192,
    "prefill_chunk": 8192,
    "tags": [
      "gemma-2-2b",
      "llama_cpp:jp6",
      "agx-orin",
      "orin-nx",
      "orin-nano"
    ]
  },
  "gemma-2-2b-it-q5m-gguf": {
    "name": "bartowski/gemma-2-2b-it-GGUF",
    "title": "Llama-3.2-1B \u276f llama.cpp Q5_K_M \u276f JetPack 6.1+",
    "url": "hf.co/bartowski/gemma-2-2b-it-GGUF/gemma-2-2b-it-Q5_K_M.gguf",
    "quantization": "q5_k_m",
    "tokenizer": "pcuenq/Llama-3.2-1B-Instruct-tokenizer",
    "max_context_len": 8192,
    "prefill_chunk": 8192,
    "tags": [
      "gemma-2-2b",
      "llama_cpp:jp6",
      "agx-orin",
      "orin-nx",
      "orin-nano"
    ]
  },
  "gemma-2-2b-it-q6k-gguf": {
    "name": "bartowski/gemma-2-2b-it-GGUF",
    "title": "Llama-3.2-1B \u276f llama.cpp Q6_K \u276f JetPack 6.1+",
    "url": "hf.co/bartowski/gemma-2-2b-it-GGUF/gemma-2-2b-it-Q6_K.gguf",
    "quantization": "q6_k",
    "tokenizer": "pcuenq/Llama-3.2-1B-Instruct-tokenizer",
    "max_context_len": 8192,
    "prefill_chunk": 8192,
    "tags": [
      "gemma-2-2b",
      "llama_cpp:jp6",
      "agx-orin",
      "orin-nx",
      "orin-nano"
    ]
  },
  "gemma-2": {
    "name": "Google Gemma",
    "tags": [
      "llm"
    ]
  },
  "gemma-2-9b": {
    "name": "Gemma 2 9B",
    "title": "Gemma 2 9B",
    "header": "gemma-header",
    "tags": [
      "gemma-2",
      "agx-orin",
      "orin-nx",
      "orin-nano"
    ],
    "max_context_len": {
      "placeholder": 8192
    },
    "prefill_chunk": {
      "placeholder": 8192
    },
    "links": {
      "meta": {
        "name": "Google",
        "url": "https://ai.google.dev/gemma",
        "color": "blue"
      },
      "hf": {
        "name": "Hugging Face",
        "url": "https://huggingface.co/google/gemma-2-9b-it",
        "color": "yellow"
      }
    }
  },
  "gemma-2-9b-it-q4f16_1-mlc": {
    "name": "google/gemma-2-9b-it-q4f16_1",
    "title": "Llama-3.2-1B \u276f MLC q4f16_1 \u276f JetPack 6.1+",
    "url": "hf.co/mlc-ai/gemma-2-9b-it-q4f16_1-MLC",
    "quantization": "q4f16_1",
    "tags": [
      "gemma-2-9b",
      "mlc:jp6",
      "agx-orin",
      "orin-nx",
      "orin-nano"
    ]
  },
  "gemma-2-9b-it-q4m-gguf": {
    "name": "bartowski/gemma-2-9b-it-GGUF",
    "title": "Llama-3.2-1B \u276f llama.cpp Q4_K_M \u276f JetPack 6.1+",
    "url": "hf.co/bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q4_K_M.gguf",
    "quantization": "q4_k_m",
    "tokenizer": "pcuenq/Llama-3.2-1B-Instruct-tokenizer",
    "max_context_len": 8192,
    "prefill_chunk": 8192,
    "tags": [
      "gemma-2-9b",
      "llama_cpp:jp6",
      "agx-orin",
      "orin-nx",
      "orin-nano"
    ]
  },
  "gemma-2-9b-it-q5m-gguf": {
    "name": "bartowski/gemma-2-9b-it-GGUF",
    "title": "Llama-3.2-1B \u276f llama.cpp Q5_K_M \u276f JetPack 6.1+",
    "url": "hf.co/bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q5_K_M.gguf",
    "quantization": "q5_k_m",
    "tokenizer": "pcuenq/Llama-3.2-1B-Instruct-tokenizer",
    "max_context_len": 8192,
    "prefill_chunk": 8192,
    "tags": [
      "gemma-2-9b",
      "llama_cpp:jp6",
      "agx-orin",
      "orin-nx",
      "orin-nano"
    ]
  },
  "gemma-2-9b-it-q6k-gguf": {
    "name": "bartowski/gemma-2-9b-it-GGUF",
    "title": "Llama-3.2-1B \u276f llama.cpp Q6_K \u276f JetPack 6.1+",
    "url": "hf.co/bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-Q6_K.gguf",
    "quantization": "q6_k",
    "tokenizer": "pcuenq/Llama-3.2-1B-Instruct-tokenizer",
    "max_context_len": 8192,
    "prefill_chunk": 8192,
    "tags": [
      "gemma-2-9b",
      "llama_cpp:jp6",
      "agx-orin",
      "orin-nx",
      "orin-nano"
    ]
  },
  "llama-3.2-1b": {
    "name": "Llama 3.2 1B",
    "title": "Llama 3.2 1B",
    "header": "llama-pilot-header",
    "tags": [
      "llama-3",
      "agx-orin",
      "orin-nx",
      "orin-nano"
    ],
    "max_context_len": {
      "placeholder": 131072
    },
    "prefill_chunk": {
      "placeholder": 8192
    },
    "links": {
      "meta": {
        "name": "Meta",
        "url": "https://www.llama.com/",
        "color": "blue"
      },
      "hf": {
        "name": "Hugging Face",
        "url": "https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct",
        "color": "yellow"
      }
    }
  },
  "llama-3.2-1b-instruct-q4f16_ft-mlc": {
    "name": "meta-llama/llama-3.2-1b-instruct-q4f16_ft",
    "title": "Llama-3.2-1B \u276f MLC q4f16_ft \u276f JetPack 6.1+",
    "url": "hf.co/dusty-nv/Llama-3.2-1B-Instruct-q4f16_ft-MLC",
    "quantization": "q4f16_ft",
    "tags": [
      "llama-3.2-1b",
      "mlc:jp6",
      "agx-orin",
      "orin-nx",
      "orin-nano"
    ]
  },
  "llama-3.2-1b-instruct-q4f16_1-mlc": {
    "name": "meta-llama/llama-3.2-1b-instruct-q4f16_1",
    "title": "Llama-3.2-1B \u276f MLC q4f16_1 \u276f JetPack 6.1+",
    "url": "hf.co/mlc-ai/Llama-3.2-1B-Instruct-q4f16_1-MLC",
    "quantization": "q4f16_1",
    "tags": [
      "llama-3.2-1b",
      "mlc:jp6",
      "agx-orin",
      "orin-nx",
      "orin-nano"
    ]
  },
  "llama-3.2-1b-instruct-q4m-gguf": {
    "name": "bartowski/Llama-3.2-1B-Instruct-GGUF",
    "title": "Llama-3.2-1B \u276f llama.cpp Q4_K_M \u276f JetPack 6.1+",
    "url": "hf.co/bartowski/Llama-3.2-1B-Instruct-GGUF/Llama-3.2-1B-Instruct-Q4_K_M.gguf",
    "quantization": "q4_k_m",
    "tokenizer": "pcuenq/Llama-3.2-1B-Instruct-tokenizer",
    "max_context_len": 8192,
    "prefill_chunk": 8192,
    "tags": [
      "llama-3.2-1b",
      "llama_cpp:jp6",
      "agx-orin",
      "orin-nx",
      "orin-nano"
    ]
  },
  "llama-3.2-1b-instruct-q5m-gguf": {
    "name": "bartowski/Llama-3.2-1B-Instruct-GGUF",
    "title": "Llama-3.2-1B \u276f llama.cpp Q5_K_M \u276f JetPack 6.1+",
    "url": "hf.co/bartowski/Llama-3.2-1B-Instruct-GGUF/Llama-3.2-1B-Instruct-Q5_K_M.gguf",
    "quantization": "q5_k_m",
    "tokenizer": "pcuenq/Llama-3.2-1B-Instruct-tokenizer",
    "max_context_len": 8192,
    "prefill_chunk": 8192,
    "tags": [
      "llama-3.2-1b",
      "llama_cpp:jp6",
      "agx-orin",
      "orin-nx",
      "orin-nano"
    ]
  },
  "llama-3.2-1b-instruct-q6k-gguf": {
    "name": "bartowski/Llama-3.2-1B-Instruct-GGUF",
    "title": "Llama-3.2-1B \u276f llama.cpp Q6_K \u276f JetPack 6.1+",
    "url": "hf.co/bartowski/Llama-3.2-1B-Instruct-GGUF/Llama-3.2-1B-Instruct-Q6_K.gguf",
    "quantization": "q6_k",
    "tokenizer": "pcuenq/Llama-3.2-1B-Instruct-tokenizer",
    "max_context_len": 8192,
    "prefill_chunk": 8192,
    "tags": [
      "llama-3.2-1b",
      "llama_cpp:jp6",
      "agx-orin",
      "orin-nx",
      "orin-nano"
    ]
  },
  "llama-3": {
    "name": "Meta Llama",
    "tags": [
      "llm"
    ]
  },
  "llama-3.2-3b": {
    "name": "Llama 3.2 3B",
    "title": "Llama 3.2 3B",
    "header": "llama-goggles-header",
    "tags": [
      "llama-3",
      "agx-orin",
      "orin-nx",
      "orin-nano"
    ],
    "max_context_len": {
      "placeholder": 131072
    },
    "prefill_chunk": {
      "placeholder": 8192
    },
    "links": {
      "meta": {
        "name": "Meta",
        "url": "https://www.llama.com/",
        "color": "blue"
      },
      "hf": {
        "name": "Hugging Face",
        "url": "https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct",
        "color": "yellow"
      }
    }
  },
  "llama-3.2-3b-instruct-q4f16_ft-mlc": {
    "name": "meta-llama/llama-3.2-3b-instruct-q4f16_ft",
    "title": "Llama-3.2-3B \u276f MLC q4f16_ft \u276f JetPack 6.1+",
    "url": "hf.co/dusty-nv/Llama-3.2-3B-Instruct-q4f16_ft-MLC",
    "quantization": "q4f16_ft",
    "tags": [
      "llama-3.2-3b",
      "mlc:jp6",
      "agx-orin",
      "orin-nx",
      "orin-nano"
    ]
  },
  "llama-3.2-3b-instruct-q4f16_1-mlc": {
    "name": "meta-llama/llama-3.2-3b-instruct-q4f16_1",
    "title": "Llama-3.2-3B \u276f MLC q4f16_1 \u276f JetPack 6.1+",
    "url": "hf.co/mlc-ai/Llama-3.2-3B-Instruct-q4f16_1-MLC",
    "quantization": "q4f16_1",
    "tags": [
      "llama-3.2-3b",
      "mlc:jp6",
      "agx-orin",
      "orin-nx",
      "orin-nano"
    ]
  },
  "llama-3.2-3b-instruct-q4m-gguf": {
    "name": "bartowski/Llama-3.2-3B-Instruct-GGUF",
    "title": "Llama-3.2-3B \u276f llama.cpp Q4_K_M \u276f JetPack 6.1+",
    "url": "hf.co/bartowski/Llama-3.2-3B-Instruct-GGUF/Llama-3.2-3B-Instruct-Q4_K_M.gguf",
    "quantization": "q4_k_m",
    "tokenizer": "pcuenq/Llama-3.2-1B-Instruct-tokenizer",
    "max_context_len": 8192,
    "prefill_chunk": 8192,
    "tags": [
      "llama-3.2-3b",
      "llama_cpp:jp6",
      "agx-orin",
      "orin-nx",
      "orin-nano"
    ]
  },
  "llama-3.2-3b-instruct-q5m-gguf": {
    "name": "bartowski/Llama-3.2-3B-Instruct-GGUF",
    "title": "Llama-3.2-3B \u276f llama.cpp Q5_K_M \u276f JetPack 6.1+",
    "url": "hf.co/bartowski/Llama-3.2-3B-Instruct-GGUF/Llama-3.2-3B-Instruct-Q5_K_M.gguf",
    "quantization": "q5_k_m",
    "tokenizer": "pcuenq/Llama-3.2-1B-Instruct-tokenizer",
    "max_context_len": 8192,
    "prefill_chunk": 8192,
    "tags": [
      "llama-3.2-3b",
      "llama_cpp:jp6",
      "agx-orin",
      "orin-nx",
      "orin-nano"
    ]
  },
  "llama-3.2-3b-instruct-q6k-gguf": {
    "name": "bartowski/Llama-3.2-3B-Instruct-GGUF",
    "title": "Llama-3.2-3B \u276f llama.cpp Q6_K \u276f JetPack 6.1+",
    "url": "hf.co/bartowski/Llama-3.2-3B-Instruct-GGUF/Llama-3.2-3B-Instruct-Q6_K.gguf",
    "quantization": "q6_k",
    "tokenizer": "pcuenq/Llama-3.2-1B-Instruct-tokenizer",
    "max_context_len": 8192,
    "prefill_chunk": 8192,
    "tags": [
      "llama-3.2-3b",
      "llama_cpp:jp6",
      "agx-orin",
      "orin-nx",
      "orin-nano"
    ]
  },
  "llama-3.1-8b": {
    "name": "Llama 3.1 8B",
    "title": "Llama 3.1 8B",
    "header": "llama-biker-header",
    "tags": [
      "llama-3",
      "agx-orin",
      "orin-nx",
      "orin-nano"
    ],
    "max_context_len": {
      "placeholder": 131072
    },
    "prefill_chunk": {
      "placeholder": 8192
    },
    "links": {
      "meta": {
        "name": "Meta",
        "url": "https://www.llama.com/",
        "color": "blue"
      },
      "hf": {
        "name": "Hugging Face",
        "url": "https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct",
        "color": "yellow"
      }
    }
  },
  "llama-3.1-8b-instruct-q4f16_ft-mlc": {
    "name": "meta-llama/llama-3.1-8b-instruct-q4f16_ft",
    "title": "Llama-3.1-8B \u276f MLC q4f16_ft \u276f JetPack 6.1+",
    "url": "hf.co/dusty-nv/Llama-3.1-8B-Instruct-q4f16_ft-MLC",
    "quantization": "q4f16_ft",
    "tags": [
      "llama-3.1-8b",
      "mlc:jp6",
      "agx-orin",
      "orin-nx",
      "orin-nano"
    ]
  },
  "llama-3.1-8b-instruct-q4f16_1-mlc": {
    "name": "meta-llama/llama-3.1-8b-instruct-q4f16_1",
    "title": "Llama-3.1-8B \u276f MLC q4f16_1 \u276f JetPack 6.1+",
    "url": "hf.co/mlc-ai/Llama-3.1-8B-Instruct-q4f16_1-MLC",
    "quantization": "q4f16_1",
    "tags": [
      "llama-3.1-8b",
      "mlc:jp6",
      "agx-orin",
      "orin-nx",
      "orin-nano"
    ]
  },
  "llama-3.1-8b-instruct-q4m-gguf": {
    "name": "bartowski/Llama-3.1-8B-Instruct-GGUF",
    "title": "Llama-3.1-8B \u276f llama.cpp Q4_K_M \u276f JetPack 6.1+",
    "url": "hf.co/bartowski/Llama-3.1-8B-Instruct-GGUF/Llama-3.1-8B-Instruct-Q4_K_M.gguf",
    "quantization": "q4_k_m",
    "tokenizer": "pcuenq/Llama-3.2-1B-Instruct-tokenizer",
    "max_context_len": 8192,
    "prefill_chunk": 8192,
    "tags": [
      "llama-3.1-8b",
      "llama_cpp:jp6",
      "agx-orin",
      "orin-nx",
      "orin-nano"
    ]
  },
  "llama-3.1-8b-instruct-q5m-gguf": {
    "name": "bartowski/Llama-3.1-8B-Instruct-GGUF",
    "title": "Llama-3.1-8B \u276f llama.cpp Q5_K_M \u276f JetPack 6.1+",
    "url": "hf.co/bartowski/Llama-3.1-8B-Instruct-GGUF/Llama-3.1-8B-Instruct-Q5_K_M.gguf",
    "quantization": "q5_k_m",
    "tokenizer": "pcuenq/Llama-3.2-1B-Instruct-tokenizer",
    "max_context_len": 8192,
    "prefill_chunk": 8192,
    "tags": [
      "llama-3.1-8b",
      "llama_cpp:jp6",
      "agx-orin",
      "orin-nx",
      "orin-nano"
    ]
  },
  "llama-3.1-8b-instruct-q6k-gguf": {
    "name": "bartowski/Llama-3.1-8B-Instruct-GGUF",
    "title": "Llama-3.1-8B \u276f llama.cpp Q6_K \u276f JetPack 6.1+",
    "url": "hf.co/bartowski/Llama-3.1-8B-Instruct-GGUF/Llama-3.1-8B-Instruct-Q6_K.gguf",
    "quantization": "q6_k",
    "tokenizer": "pcuenq/Llama-3.2-1B-Instruct-tokenizer",
    "max_context_len": 8192,
    "prefill_chunk": 8192,
    "tags": [
      "llama-3.1-8b",
      "llama_cpp:jp6",
      "agx-orin",
      "orin-nx",
      "orin-nano"
    ]
  }
}