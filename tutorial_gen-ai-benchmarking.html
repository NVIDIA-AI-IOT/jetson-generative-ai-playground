<!-- Elements added to main will be displayed on all pages -->
<!DOCTYPE html>
<html class="no-js" lang="en">
 <head>
  <meta charset="utf-8"/>
  <meta content="width=device-width,initial-scale=1" name="viewport"/>
  <meta content="Showcasing generative AI projects that run on Jetson" name="description"/>
  <link href="agent_studio.html" rel="prev"/>
  <link href="vit/index.html" rel="next"/>
  <link href="images/nvidia-favicon-rgb-16x16px@2x.png" rel="icon"/>
  <meta content="mkdocs-1.6.1, mkdocs-material-9.6.22" name="generator"/>
  <title>
   Gen AI Benchmarking 🆕 - NVIDIA Jetson AI Lab
  </title>
  <link href="assets/stylesheets/main.84d31ad4.min.css" rel="stylesheet"/>
  <link href="assets/stylesheets/palette.06af60db.min.css" rel="stylesheet"/>
  <link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
  <link href="https://fonts.googleapis.com/css?family=NVIDIA-NALA:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&amp;display=fallback" rel="stylesheet"/>
  <style>
   :root{--md-text-font:"NVIDIA-NALA";--md-code-font:"Roboto Mono"}
  </style>
  <link href="css/colors.css" rel="stylesheet"/>
  <link href="css/extra.css" rel="stylesheet"/>
  <link href="css/nvidia-font.css" rel="stylesheet"/>
  <script>
   __md_scope=new URL(".",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}
  </script>
  <script id="__analytics">
   function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-SXH8S4Y8RW"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-SXH8S4Y8RW",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-SXH8S4Y8RW",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}
  </script>
  <script>
   "undefined"!=typeof __md_analytics&&__md_analytics()
  </script>
 </head>
 <body data-md-color-accent="nv-black-green" data-md-color-primary="nv-black-green" data-md-color-scheme="nv-black-green" dir="ltr">
  <input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/>
  <input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/>
  <label class="md-overlay" for="__drawer">
  </label>
  <div data-md-component="skip">
   <a class="md-skip" href="#gen-ai-benchmarking-llms-and-vlms-on-jetson">
    Skip to content
   </a>
  </div>
  <div data-md-component="announce">
  </div>
  <header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
   <nav aria-label="Header" class="md-header__inner md-grid">
    <a aria-label="NVIDIA Jetson AI Lab" class="md-header__button md-logo" data-md-component="logo" href="index.html" title="NVIDIA Jetson AI Lab">
     <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
      <path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54">
      </path>
     </svg>
    </a>
    <label class="md-header__button md-icon" for="__drawer">
     <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
      <path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z">
      </path>
     </svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
     <div class="md-header__ellipsis">
      <div class="md-header__topic">
       <span class="md-ellipsis">
        NVIDIA Jetson AI Lab
       </span>
      </div>
      <div class="md-header__topic" data-md-component="header-topic">
       <span class="md-ellipsis">
        Gen AI Benchmarking 🆕
       </span>
      </div>
     </div>
    </div>
    <form class="md-header__option" data-md-component="palette">
     <input aria-hidden="true" class="md-option" data-md-color-accent="nv-black-green" data-md-color-media="(prefers-color-scheme: light)" data-md-color-primary="nv-black-green" data-md-color-scheme="nv-black-green" id="__palette_0" name="__palette" type="radio"/>
    </form>
    <script>
     var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}
    </script>
    <label class="md-header__button md-icon" for="__search">
     <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
      <path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5">
      </path>
     </svg>
    </label>
    <div class="md-search" data-md-component="search" role="dialog">
     <label class="md-search__overlay" for="__search">
     </label>
     <div class="md-search__inner" role="search">
      <form class="md-search__form" name="search">
       <input aria-label="Search" autocapitalize="off" autocomplete="off" autocorrect="off" class="md-search__input" data-md-component="search-query" name="query" placeholder="Search" required="" spellcheck="false" type="text"/>
       <label class="md-search__icon md-icon" for="__search">
        <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
         <path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5">
         </path>
        </svg>
        <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
         <path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z">
         </path>
        </svg>
       </label>
       <nav aria-label="Search" class="md-search__options">
        <button aria-label="Clear" class="md-search__icon md-icon" tabindex="-1" title="Clear" type="reset">
         <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
          <path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z">
          </path>
         </svg>
        </button>
       </nav>
      </form>
      <div class="md-search__output">
       <div class="md-search__scrollwrap" data-md-scrollfix="" tabindex="0">
        <div class="md-search-result" data-md-component="search-result">
         <div class="md-search-result__meta">
          Initializing search
         </div>
         <ol class="md-search-result__list" role="presentation">
         </ol>
        </div>
       </div>
      </div>
     </div>
    </div>
   </nav>
   <nav aria-label="Tabs" class="md-tabs" data-md-component="tabs">
    <div class="md-grid">
     <ul class="md-tabs__list">
      <li class="md-tabs__item">
       <a class="md-tabs__link" href="index.html">
        Home
       </a>
      </li>
      <li class="md-tabs__item">
       <a class="md-tabs__link" href="models.html">
        Models
       </a>
      </li>
      <li class="md-tabs__item md-tabs__item--active">
       <a class="md-tabs__link" href="tutorial-intro.html">
        Tutorials
       </a>
      </li>
      <li class="md-tabs__item">
       <a class="md-tabs__link" href="benchmarks.html">
        Benchmarks
       </a>
      </li>
      <li class="md-tabs__item">
       <a class="md-tabs__link" href="community_articles.html">
        Projects
       </a>
      </li>
      <li class="md-tabs__item">
       <a class="md-tabs__link" href="research.html">
        Research Group
       </a>
      </li>
     </ul>
    </div>
   </nav>
  </header>
  <div class="md-container" data-md-component="container">
   <main class="md-main" data-md-component="main">
    <div class="md-main__inner md-grid">
     <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation">
      <div class="md-sidebar__scrollwrap">
       <div class="md-sidebar__inner">
        <nav aria-label="Navigation" class="md-nav md-nav--primary md-nav--lifted" data-md-level="0">
         <label class="md-nav__title" for="__drawer">
          <a aria-label="NVIDIA Jetson AI Lab" class="md-nav__button md-logo" data-md-component="logo" href="index.html" title="NVIDIA Jetson AI Lab">
           <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
            <path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54">
            </path>
           </svg>
          </a>
          NVIDIA Jetson AI Lab
         </label>
         <ul class="md-nav__list" data-md-scrollfix="">
          <li class="md-nav__item">
           <a class="md-nav__link" href="index.html">
            <span class="md-ellipsis">
             Home
            </span>
           </a>
          </li>
          <li class="md-nav__item">
           <a class="md-nav__link" href="models.html">
            <span class="md-ellipsis">
             Models
            </span>
           </a>
          </li>
          <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
           <input checked="" class="md-nav__toggle md-toggle" id="__nav_3" type="checkbox"/>
           <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            <span class="md-ellipsis">
             Tutorials
            </span>
            <span class="md-nav__icon md-icon">
            </span>
           </label>
           <nav aria-expanded="true" aria-labelledby="__nav_3_label" class="md-nav" data-md-level="1">
            <label class="md-nav__title" for="__nav_3">
             <span class="md-nav__icon md-icon">
             </span>
             Tutorials
            </label>
            <ul class="md-nav__list" data-md-scrollfix="">
             <li class="md-nav__item">
              <a class="md-nav__link" href="tutorial-intro.html">
               <span class="md-ellipsis">
                Introduction
               </span>
              </a>
             </li>
             <li class="md-nav__item md-nav__item--nested">
              <input class="md-nav__toggle md-toggle" id="__nav_3_2" type="checkbox"/>
              <label class="md-nav__link" for="__nav_3_2" id="__nav_3_2_label" tabindex="0">
               <span class="md-ellipsis">
                Jetson Setup Guide
               </span>
               <span class="md-nav__icon md-icon">
               </span>
              </label>
              <nav aria-expanded="false" aria-labelledby="__nav_3_2_label" class="md-nav" data-md-level="2">
               <label class="md-nav__title" for="__nav_3_2">
                <span class="md-nav__icon md-icon">
                </span>
                Jetson Setup Guide
               </label>
               <ul class="md-nav__list" data-md-scrollfix="">
                <li class="md-nav__item">
                 <a class="md-nav__link" href="initial_setup_jon.html">
                  <span class="md-ellipsis">
                   🚀 Initial Setup Guide - Jetson Orin Nano
                  </span>
                 </a>
                </li>
                <li class="md-nav__item">
                 <a class="md-nav__link" href="initial_setup_jon_sdkm.html">
                  <span class="md-ellipsis">
                   🛸 Initial Setup (SDK Manager method)
                  </span>
                 </a>
                </li>
                <li class="md-nav__item">
                 <a class="md-nav__link" href="tips_ssd-docker.html">
                  <span class="md-ellipsis">
                   🔖 SSD + Docker
                  </span>
                 </a>
                </li>
                <li class="md-nav__item">
                 <a class="md-nav__link" href="tips_ram-optimization.html">
                  <span class="md-ellipsis">
                   🔖 Memory optimization
                  </span>
                 </a>
                </li>
                <li class="md-nav__item">
                 <a class="md-nav__link" href="hackathon.html">
                  <span class="md-ellipsis">
                   🏆 Hackathon Guide
                  </span>
                 </a>
                </li>
               </ul>
              </nav>
             </li>
             <li class="md-nav__item">
              <a class="md-nav__link" href="workshop_gtcdc2025.html">
               <span class="md-ellipsis">
                🌸 Jetson Workshop
               </span>
              </a>
             </li>
             <li class="md-nav__item md-nav__item--nested">
              <input class="md-nav__toggle md-toggle md-toggle--indeterminate" id="__nav_3_4" type="checkbox"/>
              <label class="md-nav__link" for="__nav_3_4" id="__nav_3_4_label" tabindex="0">
               <span class="md-ellipsis">
                AI Microservices
               </span>
               <span class="md-nav__icon md-icon">
               </span>
              </label>
              <nav aria-expanded="false" aria-labelledby="__nav_3_4_label" class="md-nav" data-md-level="2">
               <label class="md-nav__title" for="__nav_3_4">
                <span class="md-nav__icon md-icon">
                </span>
                AI Microservices
               </label>
               <ul class="md-nav__list" data-md-scrollfix="">
                <li class="md-nav__item">
                 <a class="md-nav__link" href="tutorials/microservices_intro.html">
                  <span class="md-ellipsis">
                   Microservices Intro
                  </span>
                 </a>
                </li>
                <li class="md-nav__item">
                 <a class="md-nav__link" href="tutorials/microservices_vlm.html">
                  <span class="md-ellipsis">
                   Microservices for VLM
                  </span>
                 </a>
                </li>
               </ul>
              </nav>
             </li>
             <li class="md-nav__item md-nav__item--nested">
              <input class="md-nav__toggle md-toggle md-toggle--indeterminate" id="__nav_3_5" type="checkbox"/>
              <label class="md-nav__link" for="__nav_3_5" id="__nav_3_5_label" tabindex="0">
               <span class="md-ellipsis">
                Text (LLM)
               </span>
               <span class="md-nav__icon md-icon">
               </span>
              </label>
              <nav aria-expanded="false" aria-labelledby="__nav_3_5_label" class="md-nav" data-md-level="2">
               <label class="md-nav__title" for="__nav_3_5">
                <span class="md-nav__icon md-icon">
                </span>
                Text (LLM)
               </label>
               <ul class="md-nav__list" data-md-scrollfix="">
                <li class="md-nav__item">
                 <a class="md-nav__link" href="tutorial_text-generation.html">
                  <span class="md-ellipsis">
                   text-generation-webui
                  </span>
                 </a>
                </li>
                <li class="md-nav__item">
                 <a class="md-nav__link" href="tutorial_ollama.html">
                  <span class="md-ellipsis">
                   Ollama
                  </span>
                 </a>
                </li>
                <li class="md-nav__item">
                 <a class="md-nav__link" href="tutorial_openwebui.html">
                  <span class="md-ellipsis">
                   Open WebUI
                  </span>
                 </a>
                </li>
                <li class="md-nav__item">
                 <a class="md-nav__link" href="tutorial_llamaspeak.html">
                  <span class="md-ellipsis">
                   llamaspeak
                  </span>
                 </a>
                </li>
                <li class="md-nav__item">
                 <a class="md-nav__link" href="tutorial_nano-llm.html">
                  <span class="md-ellipsis">
                   NanoLLM
                  </span>
                 </a>
                </li>
                <li class="md-nav__item">
                 <a class="md-nav__link" href="tensorrt_llm.html">
                  <span class="md-ellipsis">
                   TensorRT-LLM
                  </span>
                 </a>
                </li>
                <li class="md-nav__item">
                 <a class="md-nav__link" href="tutorial_slm.html">
                  <span class="md-ellipsis">
                   Small LLM (SLM)
                  </span>
                 </a>
                </li>
                <li class="md-nav__item">
                 <a class="md-nav__link" href="tutorial_api-examples.html">
                  <span class="md-ellipsis">
                   API Examples
                  </span>
                 </a>
                </li>
               </ul>
              </nav>
             </li>
             <li class="md-nav__item md-nav__item--nested">
              <input class="md-nav__toggle md-toggle md-toggle--indeterminate" id="__nav_3_6" type="checkbox"/>
              <label class="md-nav__link" for="__nav_3_6" id="__nav_3_6_label" tabindex="0">
               <span class="md-ellipsis">
                Text + Vision (VLM)
               </span>
               <span class="md-nav__icon md-icon">
               </span>
              </label>
              <nav aria-expanded="false" aria-labelledby="__nav_3_6_label" class="md-nav" data-md-level="2">
               <label class="md-nav__title" for="__nav_3_6">
                <span class="md-nav__icon md-icon">
                </span>
                Text + Vision (VLM)
               </label>
               <ul class="md-nav__list" data-md-scrollfix="">
                <li class="md-nav__item">
                 <a class="md-nav__link" href="tutorial_llava.html">
                  <span class="md-ellipsis">
                   LLaVA
                  </span>
                 </a>
                </li>
                <li class="md-nav__item">
                 <a class="md-nav__link" href="tutorial_live-llava.html">
                  <span class="md-ellipsis">
                   Live LLaVA
                  </span>
                 </a>
                </li>
                <li class="md-nav__item">
                 <a class="md-nav__link" href="tutorial_nano-vlm.html">
                  <span class="md-ellipsis">
                   NanoVLM
                  </span>
                 </a>
                </li>
                <li class="md-nav__item">
                 <a class="md-nav__link" href="llama_vlm.html">
                  <span class="md-ellipsis">
                   Llama 3.2 Vision
                  </span>
                 </a>
                </li>
                <li class="md-nav__item">
                 <a class="md-nav__link" href="agent_studio.html">
                  <span class="md-ellipsis">
                   Agent Studio
                  </span>
                 </a>
                </li>
               </ul>
              </nav>
             </li>
             <li class="md-nav__item md-nav__item--active">
              <input class="md-nav__toggle md-toggle" id="__toc" type="checkbox"/>
              <label class="md-nav__link md-nav__link--active" for="__toc">
               <span class="md-ellipsis">
                Gen AI Benchmarking 🆕
               </span>
               <span class="md-nav__icon md-icon">
               </span>
              </label>
              <a class="md-nav__link md-nav__link--active" href="tutorial_gen-ai-benchmarking.html">
               <span class="md-ellipsis">
                Gen AI Benchmarking 🆕
               </span>
              </a>
              <nav aria-label="Table of contents" class="md-nav md-nav--secondary">
               <label class="md-nav__title" for="__toc">
                <span class="md-nav__icon md-icon">
                </span>
                Table of contents
               </label>
               <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix="">
                <li class="md-nav__item">
                 <a class="md-nav__link" href="#what-were-measuring-and-what-were-not">
                  <span class="md-ellipsis">
                   What We're Measuring (and What We're Not)
                  </span>
                 </a>
                </li>
                <li class="md-nav__item">
                 <a class="md-nav__link" href="#1-preparing-your-jetson-environment">
                  <span class="md-ellipsis">
                   1. Preparing Your Jetson Environment
                  </span>
                 </a>
                 <nav aria-label="1. Preparing Your Jetson Environment" class="md-nav">
                  <ul class="md-nav__list">
                   <li class="md-nav__item">
                    <a class="md-nav__link" href="#get-the-vllm-container">
                     <span class="md-ellipsis">
                      Get the vLLM Container
                     </span>
                    </a>
                   </li>
                  </ul>
                 </nav>
                </li>
                <li class="md-nav__item">
                 <a class="md-nav__link" href="#2-the-benchmarking-workflow">
                  <span class="md-ellipsis">
                   2. The Benchmarking Workflow
                  </span>
                 </a>
                 <nav aria-label="2. The Benchmarking Workflow" class="md-nav">
                  <ul class="md-nav__list">
                   <li class="md-nav__item">
                    <a class="md-nav__link" href="#step-1-open-two-terminals">
                     <span class="md-ellipsis">
                      Step 1: Open Two Terminals
                     </span>
                    </a>
                   </li>
                   <li class="md-nav__item">
                    <a class="md-nav__link" href="#step-2-launch-the-container">
                     <span class="md-ellipsis">
                      Step 2: Launch the Container
                     </span>
                    </a>
                   </li>
                   <li class="md-nav__item">
                    <a class="md-nav__link" href="#step-3-serve-the-model-terminal-1">
                     <span class="md-ellipsis">
                      Step 3: Serve the Model (Terminal 1)
                     </span>
                    </a>
                   </li>
                   <li class="md-nav__item">
                    <a class="md-nav__link" href="#step-4-warm-up-the-model-terminal-2">
                     <span class="md-ellipsis">
                      Step 4: Warm Up the Model (Terminal 2)
                     </span>
                    </a>
                   </li>
                   <li class="md-nav__item">
                    <a class="md-nav__link" href="#step-5-run-the-official-benchmark-terminal-2">
                     <span class="md-ellipsis">
                      Step 5: Run the Official Benchmark (Terminal 2)
                     </span>
                    </a>
                   </li>
                  </ul>
                 </nav>
                </li>
                <li class="md-nav__item">
                 <a class="md-nav__link" href="#3-analyzing-your-results">
                  <span class="md-ellipsis">
                   3. Analyzing Your Results
                  </span>
                 </a>
                 <nav aria-label="3. Analyzing Your Results" class="md-nav">
                  <ul class="md-nav__list">
                   <li class="md-nav__item">
                    <a class="md-nav__link" href="#key-metrics-explained">
                     <span class="md-ellipsis">
                      Key Metrics Explained
                     </span>
                    </a>
                   </li>
                   <li class="md-nav__item">
                    <a class="md-nav__link" href="#concurrency-1-vs-8-the-trade-off">
                     <span class="md-ellipsis">
                      Concurrency 1 vs. 8: The Trade-Off
                     </span>
                    </a>
                   </li>
                  </ul>
                 </nav>
                </li>
               </ul>
              </nav>
             </li>
             <li class="md-nav__item md-nav__item--nested">
              <input class="md-nav__toggle md-toggle md-toggle--indeterminate" id="__nav_3_8" type="checkbox"/>
              <div class="md-nav__link md-nav__container">
               <a class="md-nav__link" href="vit/index.html">
                <span class="md-ellipsis">
                 Vision Transformers (ViT)
                </span>
               </a>
               <label class="md-nav__link" for="__nav_3_8" id="__nav_3_8_label" tabindex="0">
                <span class="md-nav__icon md-icon">
                </span>
               </label>
              </div>
              <nav aria-expanded="false" aria-labelledby="__nav_3_8_label" class="md-nav" data-md-level="2">
               <label class="md-nav__title" for="__nav_3_8">
                <span class="md-nav__icon md-icon">
                </span>
                Vision Transformers (ViT)
               </label>
               <ul class="md-nav__list" data-md-scrollfix="">
                <li class="md-nav__item">
                 <a class="md-nav__link" href="vit/tutorial_efficientvit.html">
                  <span class="md-ellipsis">
                   EfficientViT
                  </span>
                 </a>
                </li>
                <li class="md-nav__item">
                 <a class="md-nav__link" href="vit/tutorial_nanoowl.html">
                  <span class="md-ellipsis">
                   NanoOWL
                  </span>
                 </a>
                </li>
                <li class="md-nav__item">
                 <a class="md-nav__link" href="vit/tutorial_nanosam.html">
                  <span class="md-ellipsis">
                   NanoSAM
                  </span>
                 </a>
                </li>
                <li class="md-nav__item">
                 <a class="md-nav__link" href="vit/tutorial_sam.html">
                  <span class="md-ellipsis">
                   SAM
                  </span>
                 </a>
                </li>
                <li class="md-nav__item">
                 <a class="md-nav__link" href="vit/tutorial_tam.html">
                  <span class="md-ellipsis">
                   TAM
                  </span>
                 </a>
                </li>
                <li class="md-nav__item">
                 <a class="md-nav__link" href="tutorial_distillation.html">
                  <span class="md-ellipsis">
                   📑 Knowledge Distillation
                  </span>
                 </a>
                </li>
               </ul>
              </nav>
             </li>
             <li class="md-nav__item md-nav__item--nested">
              <input class="md-nav__toggle md-toggle md-toggle--indeterminate" id="__nav_3_9" type="checkbox"/>
              <label class="md-nav__link" for="__nav_3_9" id="__nav_3_9_label" tabindex="0">
               <span class="md-ellipsis">
                Robotics &amp; Embodiment
               </span>
               <span class="md-nav__icon md-icon">
               </span>
              </label>
              <nav aria-expanded="false" aria-labelledby="__nav_3_9_label" class="md-nav" data-md-level="2">
               <label class="md-nav__title" for="__nav_3_9">
                <span class="md-nav__icon md-icon">
                </span>
                Robotics &amp; Embodiment
               </label>
               <ul class="md-nav__list" data-md-scrollfix="">
                <li class="md-nav__item">
                 <a class="md-nav__link" href="cosmos.html">
                  <span class="md-ellipsis">
                   Cosmos
                  </span>
                 </a>
                </li>
                <li class="md-nav__item">
                 <a class="md-nav__link" href="genesis.html">
                  <span class="md-ellipsis">
                   Genesis 🆕
                  </span>
                 </a>
                </li>
                <li class="md-nav__item">
                 <a class="md-nav__link" href="lerobot.html">
                  <span class="md-ellipsis">
                   LeRobot
                  </span>
                 </a>
                </li>
                <li class="md-nav__item">
                 <a class="md-nav__link" href="ros.html">
                  <span class="md-ellipsis">
                   ROS2 Nodes
                  </span>
                 </a>
                </li>
                <li class="md-nav__item">
                 <a class="md-nav__link" href="openvla.html">
                  <span class="md-ellipsis">
                   OpenVLA
                  </span>
                 </a>
                </li>
                <li class="md-nav__item">
                 <a class="md-nav__link" href="robopoint.html">
                  <span class="md-ellipsis">
                   RoboPoint 🆕
                  </span>
                 </a>
                </li>
               </ul>
              </nav>
             </li>
             <li class="md-nav__item md-nav__item--nested">
              <input class="md-nav__toggle md-toggle" id="__nav_3_10" type="checkbox"/>
              <label class="md-nav__link" for="__nav_3_10" id="__nav_3_10_label" tabindex="0">
               <span class="md-ellipsis">
                Image Generation
               </span>
               <span class="md-nav__icon md-icon">
               </span>
              </label>
              <nav aria-expanded="false" aria-labelledby="__nav_3_10_label" class="md-nav" data-md-level="2">
               <label class="md-nav__title" for="__nav_3_10">
                <span class="md-nav__icon md-icon">
                </span>
                Image Generation
               </label>
               <ul class="md-nav__list" data-md-scrollfix="">
                <li class="md-nav__item">
                 <a class="md-nav__link" href="tutorial_comfyui_flux.html">
                  <span class="md-ellipsis">
                   Flux &amp; ComfyUI
                  </span>
                 </a>
                </li>
                <li class="md-nav__item">
                 <a class="md-nav__link" href="tutorial_stable-diffusion.html">
                  <span class="md-ellipsis">
                   Stable Diffusion
                  </span>
                 </a>
                </li>
                <li class="md-nav__item">
                 <a class="md-nav__link" href="tutorial_stable-diffusion-xl.html">
                  <span class="md-ellipsis">
                   Stable Diffusion XL
                  </span>
                 </a>
                </li>
                <li class="md-nav__item">
                 <a class="md-nav__link" href="nerf.html">
                  <span class="md-ellipsis">
                   nerfstudio
                  </span>
                 </a>
                </li>
               </ul>
              </nav>
             </li>
             <li class="md-nav__item md-nav__item--nested">
              <input class="md-nav__toggle md-toggle" id="__nav_3_11" type="checkbox"/>
              <label class="md-nav__link" for="__nav_3_11" id="__nav_3_11_label" tabindex="0">
               <span class="md-ellipsis">
                RAG &amp; Vector Database
               </span>
               <span class="md-nav__icon md-icon">
               </span>
              </label>
              <nav aria-expanded="false" aria-labelledby="__nav_3_11_label" class="md-nav" data-md-level="2">
               <label class="md-nav__title" for="__nav_3_11">
                <span class="md-nav__icon md-icon">
                </span>
                RAG &amp; Vector Database
               </label>
               <ul class="md-nav__list" data-md-scrollfix="">
                <li class="md-nav__item">
                 <a class="md-nav__link" href="tutorial_nanodb.html">
                  <span class="md-ellipsis">
                   NanoDB
                  </span>
                 </a>
                </li>
                <li class="md-nav__item">
                 <a class="md-nav__link" href="tutorial_llamaindex.html">
                  <span class="md-ellipsis">
                   LlamaIndex
                  </span>
                 </a>
                </li>
                <li class="md-nav__item">
                 <a class="md-nav__link" href="tutorial_jetson-copilot.html">
                  <span class="md-ellipsis">
                   Jetson Copilot
                  </span>
                 </a>
                </li>
               </ul>
              </nav>
             </li>
             <li class="md-nav__item md-nav__item--nested">
              <input class="md-nav__toggle md-toggle" id="__nav_3_12" type="checkbox"/>
              <label class="md-nav__link" for="__nav_3_12" id="__nav_3_12_label" tabindex="0">
               <span class="md-ellipsis">
                SDK Integrations
               </span>
               <span class="md-nav__icon md-icon">
               </span>
              </label>
              <nav aria-expanded="false" aria-labelledby="__nav_3_12_label" class="md-nav" data-md-level="2">
               <label class="md-nav__title" for="__nav_3_12">
                <span class="md-nav__icon md-icon">
                </span>
                SDK Integrations
               </label>
               <ul class="md-nav__list" data-md-scrollfix="">
                <li class="md-nav__item">
                 <a class="md-nav__link" href="tutorial_holoscan.html">
                  <span class="md-ellipsis">
                   Holoscan SDK
                  </span>
                 </a>
                </li>
                <li class="md-nav__item">
                 <a class="md-nav__link" href="tutorial_jps.html">
                  <span class="md-ellipsis">
                   Jetson Platform Services
                  </span>
                 </a>
                </li>
                <li class="md-nav__item">
                 <a class="md-nav__link" href="tutorial_gapi_workflows.html">
                  <span class="md-ellipsis">
                   Gapi Workflows
                  </span>
                 </a>
                </li>
                <li class="md-nav__item">
                 <a class="md-nav__link" href="tutorial_gapi_microservices.html">
                  <span class="md-ellipsis">
                   Gapi Micro Services
                  </span>
                 </a>
                </li>
                <li class="md-nav__item">
                 <a class="md-nav__link" href="tutorial_ultralytics.html">
                  <span class="md-ellipsis">
                   Ultralytics YOLOv8
                  </span>
                 </a>
                </li>
               </ul>
              </nav>
             </li>
             <li class="md-nav__item md-nav__item--nested">
              <input class="md-nav__toggle md-toggle" id="__nav_3_13" type="checkbox"/>
              <label class="md-nav__link" for="__nav_3_13" id="__nav_3_13_label" tabindex="0">
               <span class="md-ellipsis">
                Audio
               </span>
               <span class="md-nav__icon md-icon">
               </span>
              </label>
              <nav aria-expanded="false" aria-labelledby="__nav_3_13_label" class="md-nav" data-md-level="2">
               <label class="md-nav__title" for="__nav_3_13">
                <span class="md-nav__icon md-icon">
                </span>
                Audio
               </label>
               <ul class="md-nav__list" data-md-scrollfix="">
                <li class="md-nav__item">
                 <a class="md-nav__link" href="tutorial_whisper.html">
                  <span class="md-ellipsis">
                   Whisper
                  </span>
                 </a>
                </li>
                <li class="md-nav__item">
                 <a class="md-nav__link" href="tutorial_audiocraft.html">
                  <span class="md-ellipsis">
                   AudioCraft
                  </span>
                 </a>
                </li>
                <li class="md-nav__item">
                 <a class="md-nav__link" href="tutorial_voicecraft.html">
                  <span class="md-ellipsis">
                   VoiceCraft
                  </span>
                 </a>
                </li>
               </ul>
              </nav>
             </li>
            </ul>
           </nav>
          </li>
          <li class="md-nav__item">
           <a class="md-nav__link" href="benchmarks.html">
            <span class="md-ellipsis">
             Benchmarks
            </span>
           </a>
          </li>
          <li class="md-nav__item">
           <a class="md-nav__link" href="community_articles.html">
            <span class="md-ellipsis">
             Projects
            </span>
           </a>
          </li>
          <li class="md-nav__item">
           <a class="md-nav__link" href="research.html">
            <span class="md-ellipsis">
             Research Group
            </span>
           </a>
          </li>
         </ul>
        </nav>
       </div>
      </div>
     </div>
     <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc">
      <div class="md-sidebar__scrollwrap">
       <div class="md-sidebar__inner">
        <nav aria-label="Table of contents" class="md-nav md-nav--secondary">
         <label class="md-nav__title" for="__toc">
          <span class="md-nav__icon md-icon">
          </span>
          Table of contents
         </label>
         <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix="">
          <li class="md-nav__item">
           <a class="md-nav__link" href="#what-were-measuring-and-what-were-not">
            <span class="md-ellipsis">
             What We're Measuring (and What We're Not)
            </span>
           </a>
          </li>
          <li class="md-nav__item">
           <a class="md-nav__link" href="#1-preparing-your-jetson-environment">
            <span class="md-ellipsis">
             1. Preparing Your Jetson Environment
            </span>
           </a>
           <nav aria-label="1. Preparing Your Jetson Environment" class="md-nav">
            <ul class="md-nav__list">
             <li class="md-nav__item">
              <a class="md-nav__link" href="#get-the-vllm-container">
               <span class="md-ellipsis">
                Get the vLLM Container
               </span>
              </a>
             </li>
            </ul>
           </nav>
          </li>
          <li class="md-nav__item">
           <a class="md-nav__link" href="#2-the-benchmarking-workflow">
            <span class="md-ellipsis">
             2. The Benchmarking Workflow
            </span>
           </a>
           <nav aria-label="2. The Benchmarking Workflow" class="md-nav">
            <ul class="md-nav__list">
             <li class="md-nav__item">
              <a class="md-nav__link" href="#step-1-open-two-terminals">
               <span class="md-ellipsis">
                Step 1: Open Two Terminals
               </span>
              </a>
             </li>
             <li class="md-nav__item">
              <a class="md-nav__link" href="#step-2-launch-the-container">
               <span class="md-ellipsis">
                Step 2: Launch the Container
               </span>
              </a>
             </li>
             <li class="md-nav__item">
              <a class="md-nav__link" href="#step-3-serve-the-model-terminal-1">
               <span class="md-ellipsis">
                Step 3: Serve the Model (Terminal 1)
               </span>
              </a>
             </li>
             <li class="md-nav__item">
              <a class="md-nav__link" href="#step-4-warm-up-the-model-terminal-2">
               <span class="md-ellipsis">
                Step 4: Warm Up the Model (Terminal 2)
               </span>
              </a>
             </li>
             <li class="md-nav__item">
              <a class="md-nav__link" href="#step-5-run-the-official-benchmark-terminal-2">
               <span class="md-ellipsis">
                Step 5: Run the Official Benchmark (Terminal 2)
               </span>
              </a>
             </li>
            </ul>
           </nav>
          </li>
          <li class="md-nav__item">
           <a class="md-nav__link" href="#3-analyzing-your-results">
            <span class="md-ellipsis">
             3. Analyzing Your Results
            </span>
           </a>
           <nav aria-label="3. Analyzing Your Results" class="md-nav">
            <ul class="md-nav__list">
             <li class="md-nav__item">
              <a class="md-nav__link" href="#key-metrics-explained">
               <span class="md-ellipsis">
                Key Metrics Explained
               </span>
              </a>
             </li>
             <li class="md-nav__item">
              <a class="md-nav__link" href="#concurrency-1-vs-8-the-trade-off">
               <span class="md-ellipsis">
                Concurrency 1 vs. 8: The Trade-Off
               </span>
              </a>
             </li>
            </ul>
           </nav>
          </li>
         </ul>
        </nav>
       </div>
      </div>
     </div>
     <div class="md-content" data-md-component="content">
      <article class="md-content__inner md-typeset">
       <h1 id="gen-ai-benchmarking-llms-and-vlms-on-jetson">
        Gen AI Benchmarking: LLMs and VLMs on Jetson
       </h1>
       <p>
        In this tutorial, we will walk you through benchmarking Large Language Models (LLMs) and Vision Language Models (VLMs) on your Jetson. For this guide, we'll use vLLM as our inference engine of choice due to its high throughput and efficiency. We'll focus on measuring the model's speed and performance, which are critical to give you an idea of how your system will react under different loads.
       </p>
       <p>
        We will begin by serving the model, focusing on the key arguments to pass to vLLM. Then, we will capture and analyze the most critical metrics from our benchmark.
       </p>
       <h2 id="what-were-measuring-and-what-were-not">
        What We're Measuring (and What We're Not)
       </h2>
       <p>
        In this tutorial, we are measuring the performance of the model, not its quality. Our goal is to answer questions like:
       </p>
       <ul>
        <li>
         How fast is it? (Latency)
        </li>
        <li>
         How much work can it handle at once? (Throughput)
        </li>
       </ul>
       <p>
        We will not be evaluating the model's accuracy or how "smart" its answers are. We'll focus on these three key metrics:
       </p>
       <p>
        <strong>
         Time to First Token (TTFT)
        </strong>
        : How long a user has to wait before the model starts generating a response. This is crucial for a responsive user experience. The initial delay before the first token appears exists because the model must first process your entire input prompt (a step called 'prefill') to compute its internal state, known as the KV cache. This upfront work is what allows vLLM to generate all subsequent tokens extremely fast.
       </p>
       <p>
        <strong>
         Output Token Throughput (tok/s)
        </strong>
        : The total number of tokens the model can generate per second across all concurrent requests. This is our main measure of overall server capacity.
       </p>
       <p>
        <strong>
         Inter-Token Latency (ITL)
        </strong>
        : The average delay between each token generated in the response. This affects how smoothly the text appears to "stream" to the user.
       </p>
       <p>
        Here is a simple example to illustrate these metrics:
       </p>
       <p>
        Imagine a drone using an onboard VLM to detect fires from its camera feed. The model is constantly processing this feed with the prompt, "Do you see a fire?" and is connected to an alert system.
       </p>
       <p>
        In this scenario, a low TTFT is critical, as it's the time from the camera seeing fire to the system generating the first word of an alert like "Yes...". The Output Token Throughput then determines how quickly the model can provide a full, detailed description like "...a large fire is spreading in the north quadrant."
       </p>
       <h2 id="1-preparing-your-jetson-environment">
        1. Preparing Your Jetson Environment
       </h2>
       <p>
        First, before starting the benchmark, we recommend you reboot the unit to make sure we are starting from a clean state. We also recommend setting your Jetson to MAXN mode.
       </p>
       <p>
        You can do that by executing the following command.
       </p>
       <div class="highlight">
        <pre><span></span><code>sudo<span class="w"> </span>nvpmodel<span class="w"> </span>-m<span class="w"> </span><span class="m">0</span>
</code></pre>
       </div>
       <h3 id="get-the-vllm-container">
        Get the vLLM Container
       </h3>
       <p>
        We will use a pre-built Docker container published by NVIDIA that has vLLM and all its dependencies. This guarantees a consistent environment for reproducible results and saves us from the complex process of building vLLM from source, which is necessary because official binaries are not provided for the Jetson platform.
       </p>
       <p>
        Pull the container using the following command:
       </p>
       <div class="highlight">
        <pre><span></span><code>docker<span class="w"> </span>pull<span class="w"> </span>nvcr.io/nvidia/vllm:25.09-py3
</code></pre>
       </div>
       <h2 id="2-the-benchmarking-workflow">
        2. The Benchmarking Workflow
       </h2>
       <p>
        The benchmarking process requires two separate terminals because we need one to serve the model and another to send benchmark requests to it.
       </p>
       <h3 id="step-1-open-two-terminals">
        Step 1: Open Two Terminals
       </h3>
       <p>
        Open two terminal windows on your Jetson. We will refer to them as:
       </p>
       <ul>
        <li>
         Terminal 1 (Serving Terminal)
        </li>
        <li>
         Terminal 2 (Benchmark Terminal)
        </li>
       </ul>
       <h3 id="step-2-launch-the-container">
        Step 2: Launch the Container
       </h3>
       <p>
        In Terminal 1, start and enter the container:
       </p>
       <div class="highlight">
        <pre><span></span><code>sudo<span class="w"> </span>docker<span class="w"> </span>run<span class="w"> </span>--rm<span class="w"> </span>-it<span class="w"> </span>--network<span class="w"> </span>host<span class="w"> </span>--shm-size<span class="o">=</span>16g<span class="w"> </span>--ulimit<span class="w"> </span><span class="nv">memlock</span><span class="o">=</span>-1<span class="w"> </span>--ulimit<span class="w"> </span><span class="nv">stack</span><span class="o">=</span><span class="m">67108864</span><span class="w"> </span>--runtime<span class="o">=</span>nvidia<span class="w"> </span>--name<span class="o">=</span>vllm<span class="w"> </span>nvcr.io/nvidia/vllm:25.09-py3
</code></pre>
       </div>
       <p>
        Now, in Terminal 2, let's execute this command to access the same running container:
       </p>
       <div class="highlight">
        <pre><span></span><code>sudo<span class="w"> </span>docker<span class="w"> </span><span class="nb">exec</span><span class="w"> </span>-it<span class="w"> </span>vllm<span class="w"> </span>bash
</code></pre>
       </div>
       <p>
        You should now have two terminals, both inside the same running Docker container.
       </p>
       <h3 id="step-3-serve-the-model-terminal-1">
        Step 3: Serve the Model (Terminal 1)
       </h3>
       <p>
        In your Serving Terminal, run the following command to load the Meta-Llama-3.1-8B quantized model and start the server. This command tells vLLM to prepare the model to accept requests.
       </p>
       <div class="highlight">
        <pre><span></span><code><span class="nv">VLLM_ATTENTION_BACKEND</span><span class="o">=</span>FLASHINFER<span class="w"> </span>vllm<span class="w"> </span>serve<span class="w"> </span><span class="s2">"RedHatAI/Meta-Llama-3.1-8B-Instruct-quantized.w4a16"</span><span class="w"> </span><span class="se">\</span>
--port<span class="w"> </span><span class="s2">"8000"</span><span class="w"> </span><span class="se">\</span>
--host<span class="w"> </span><span class="s2">"0.0.0.0"</span><span class="w"> </span><span class="se">\</span>
--trust_remote_code<span class="w"> </span><span class="se">\</span>
--swap-space<span class="w"> </span><span class="m">16</span><span class="w"> </span><span class="se">\</span>
--max-seq-len<span class="w"> </span><span class="m">32000</span><span class="w"> </span><span class="se">\</span>
--max-model-len<span class="w"> </span><span class="m">32000</span><span class="w"> </span><span class="se">\</span>
--tensor-parallel-size<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
--max-num-seqs<span class="w"> </span><span class="m">1024</span><span class="w"> </span><span class="se">\</span>
--gpu-memory-utilization<span class="w"> </span><span class="m">0</span>.8
</code></pre>
       </div>
       <p>
        For this tutorial, we will be using this checkpoint
        <code>
         RedHatAI/Meta-Llama-3.1-8B-Instruct-quantized.w4a16
        </code>
        .
       </p>
       <p>
        It is Llama 3.1 8B Instruct W4A16 quantized. But you can replace that checkpoint with any model checkpoint from Hugging Face, whether it is an LLM or a VLM.
       </p>
       <p>
        <strong>
         What these arguments mean:
        </strong>
       </p>
       <ul>
        <li>
         <code>
          VLLM_ATTENTION_BACKEND=FLASHINFER
         </code>
         : We explicitly set this environment variable to use the FlashInfer backend. FlashInfer is a highly optimized library that significantly speeds up the core self-attention mechanism on NVIDIA GPUs by reducing memory traffic. Setting this ensures we are leveraging the fastest possible implementation for our benchmark. However, some models may not be fully compatible and could give a "CUDA Kernel not supported" error. If this happens, you can simply try an alternative like
         <code>
          VLLM_ATTENTION_BACKEND=FLASH_ATTN
         </code>
         .
        </li>
        <li>
         <code>
          --gpu-memory-utilization 0.8
         </code>
         : lets vLLM use ~80% of the total memory. Model weights load first and the remaining capacity within that 80% is pre-allocated to the KV cache.
        </li>
        <li>
         <code>
          --max-seq-len 32000
         </code>
         : Sets an upper limit on the input sequence length (the prompt only) that vLLM will accept for a single request.
        </li>
        <li>
         <code>
          --max-seq-len 32000
         </code>
         : Sets an upper bound on the model's context window (i.e. prompt tokens + output tokens) for a single request. vLLM will attempt to enforce this as the maximum total token count in memory for that request.
        </li>
       </ul>
       <p>
        Wait until you see the confirmation message that the server is running. It will look exactly like this:
       </p>
       <div class="highlight">
        <pre><span></span><code>(APIServer pid=92) INFO:     Waiting for application startup.
(APIServer pid=92) INFO:     Application startup complete.
</code></pre>
       </div>
       <p>
        Leave this terminal running. Do not close it.
       </p>
       <h3 id="step-4-warm-up-the-model-terminal-2">
        Step 4: Warm Up the Model (Terminal 2)
       </h3>
       <p>
        Before we run the real benchmark, we need to perform a "warm-up." This is a practice run that populates vLLM's internal caches, especially the
        <a href="https://docs.vllm.ai/en/latest/features/automatic_prefix_caching.html">
         prefix cache
        </a>
        , allowing it to achieve its true peak performance during the actual test.
       </p>
       <p>
        In your Benchmark Terminal, run this command. The results from this run should be ignored.
       </p>
       <div class="highlight">
        <pre><span></span><code>vllm<span class="w"> </span>bench<span class="w"> </span>serve<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--dataset-name<span class="w"> </span>random<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--model<span class="w"> </span>RedHatAI/Meta-Llama-3.1-8B-Instruct-quantized.w4a16<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num-prompts<span class="w"> </span><span class="m">50</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--percentile-metrics<span class="w"> </span>ttft,tpot,itl,e2el<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--random-input-len<span class="w"> </span><span class="m">2048</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--random-output-len<span class="w"> </span><span class="m">128</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--max-concurrency<span class="w"> </span><span class="m">1</span>
</code></pre>
       </div>
       <p>
        <strong>
         A Note on Dataset Choice.
        </strong>
        Since this tutorial is about performance (speed) rather than quality, the content of the dataset doesn't directly change latency/throughput; what matters are request shapes (token lengths), sampling/decoding settings, and concurrency. For synthetic runs, we use
        <code>
         --dataset-name random
        </code>
        , which lets us fix token counts precisely.
       </p>
       <p>
        We set
        <code>
         --random-input-len 2048
        </code>
        and
        <code>
         --random-output-len 128
        </code>
        . For a RAG-style workload, increase
        <code>
         --random-input-len
        </code>
        to account for the retrieved context.
       </p>
       <p>
        However, if you are benchmarking a Vision Language Model, it is crucial to use a dataset that includes images for meaningful results. For a VLM, you would need to change the
        <code>
         --dataset-name
        </code>
        argument and swap it with the right argument to load the dataset of your choice. We recommend using
        <code>
         lmarena-ai/vision-arena-bench-v0.1
        </code>
        .
       </p>
       <p>
        The final command will look like this for the VLM:
       </p>
       <div class="highlight">
        <pre><span></span><code>vllm<span class="w"> </span>bench<span class="w"> </span>serve<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--dataset-name<span class="w"> </span>hf<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--dataset-path<span class="w"> </span>lmarena-ai/vision-arena-bench-v0.1<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--hf-split<span class="w"> </span>train<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--model<span class="w"> </span>&lt;your_vlm_model&gt;<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num-prompts<span class="w"> </span><span class="m">50</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--percentile-metrics<span class="w"> </span>ttft,tpot,itl,e2el<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--hf-output-len<span class="w"> </span><span class="m">128</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--max-concurrency<span class="w"> </span><span class="m">1</span>
</code></pre>
       </div>
       <p>
        For more information about the flags the vllm bench serve can take, please check out
        <a href="https://docs.vllm.ai/en/v0.10.1/cli/bench/serve.html#options">
         vLLM's documentation page
        </a>
        .
       </p>
       <p>
        For the rest of the tutorial, we will be continuing with our example on the Llama 3.1 8B Instruct benchmark.
       </p>
       <h3 id="step-5-run-the-official-benchmark-terminal-2">
        Step 5: Run the Official Benchmark (Terminal 2)
       </h3>
       <p>
        Now you're ready to collect the real performance data. We will run the test twice: once to measure single-user performance and once to simulate a heavier load.
       </p>
       <p>
        <strong>
         Benchmark 1: Single-User Performance (Concurrency = 1)
        </strong>
       </p>
       <p>
        This test measures the best-case scenario for an individual user.
       </p>
       <div class="highlight">
        <pre><span></span><code>vllm<span class="w"> </span>bench<span class="w"> </span>serve<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--dataset-name<span class="w"> </span>random<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--model<span class="w"> </span>RedHatAI/Meta-Llama-3.1-8B-Instruct-quantized.w4a16<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num-prompts<span class="w"> </span><span class="m">50</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--percentile-metrics<span class="w"> </span>ttft,tpot,itl,e2el<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--random-input-len<span class="w"> </span><span class="m">2048</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--random-output-len<span class="w"> </span><span class="m">128</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--max-concurrency<span class="w"> </span><span class="m">1</span>
</code></pre>
       </div>
       <p>
        <strong>
         Benchmark 2: Multi-User Performance (Concurrency = 8)
        </strong>
       </p>
       <p>
        This test simulates 8 users sending requests at the same time to see how the system performs under load.
       </p>
       <div class="highlight">
        <pre><span></span><code>vllm<span class="w"> </span>bench<span class="w"> </span>serve<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--dataset-name<span class="w"> </span>random<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--model<span class="w"> </span>RedHatAI/Meta-Llama-3.1-8B-Instruct-quantized.w4a16<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num-prompts<span class="w"> </span><span class="m">50</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--percentile-metrics<span class="w"> </span>ttft,tpot,itl,e2el<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--random-input-len<span class="w"> </span><span class="m">2048</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--random-output-len<span class="w"> </span><span class="m">128</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--max-concurrency<span class="w"> </span><span class="m">8</span>
</code></pre>
       </div>
       <h2 id="3-analyzing-your-results">
        3. Analyzing Your Results
       </h2>
       <p>
        After your benchmark runs, you will get a summary table. Let's break down what the key numbers mean using the sample output below.
       </p>
       <div class="highlight">
        <pre><span></span><code>============ Serving Benchmark Result ============
Successful requests:                     50        
Maximum request concurrency:             1         
Benchmark duration (s):                  233.17    
Total input tokens:                      10058     
Total generated tokens:                  10303     
Request throughput (req/s):              0.21      
Output token throughput (tok/s):         44.19     
Total Token throughput (tok/s):          87.32     
---------------Time to First Token----------------
Mean TTFT (ms):                          32.02     
Median TTFT (ms):                        31.38     
P99 TTFT (ms):                           38.12     
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          22.61     
Median TPOT (ms):                        22.56     
P99 TPOT (ms):                           24.97     
---------------Inter-token Latency----------------
Mean ITL (ms):                           22.47     
Median ITL (ms):                         22.58     
P99 ITL (ms):                            23.79     
----------------End-to-end Latency----------------
Mean E2EL (ms):                          4663.04   
Median E2EL (ms):                        3450.02   
P99 E2EL (ms):                           15030.27  
==================================================
</code></pre>
       </div>
       <h3 id="key-metrics-explained">
        Key Metrics Explained
       </h3>
       <p>
        <strong>
         Output token throughput (tok/s): 44.19
        </strong>
       </p>
       <p>
        This metric measures the generation speed for a single user, and a result of 44.19 tokens/second indicates a very strong processing capability for a single request, delivering text much faster than a person can read.
       </p>
       <p>
        <strong>
         Mean TTFT (ms): 32.02
        </strong>
       </p>
       <p>
        This is the average initial wait time before a response begins generating. An extremely low result of just 32.02 milliseconds means the application will feel instantaneous and highly responsive to the user.
       </p>
       <p>
        In the context of VLMs, this number would usually be higher, since we are not dealing with the text prompt only; we are dealing with an image as well.
       </p>
       <p>
        <strong>
         Mean ITL (ms): 22.47
        </strong>
       </p>
       <p>
        This measures the average time gap between each generated token after the first one. A low value of 22.47 milliseconds is excellent, as it translates directly to a fast and smooth streaming experience for the user.
       </p>
       <h3 id="concurrency-1-vs-8-the-trade-off">
        Concurrency 1 vs. 8: The Trade-Off
       </h3>
       <p>
        When you compare your results, you'll likely see a trade-off:
       </p>
       <ul>
        <li>
         Going from concurrency 1 to 8, the Output Token Throughput should increase significantly. The system is doing more total work.
        </li>
        <li>
         However, the Mean TTFT and Mean ITL will also likely increase. Since the Jetson is now splitting its time between 8 requests instead of 1, each individual request takes longer to process.
        </li>
       </ul>
       <p>
        This is the classic trade-off between overall capacity and individual user experience. Your benchmark results help you find the right balance for your application.
       </p>
       <div class="admonition note">
        <p class="admonition-title">
         Note
        </p>
        <p>
         The term "user" in this tutorial could mean the entity which consumes the output of the model which could be a robotic application using the model in a drone, a humanoid, or simply you using it as a local LLM inference hardware.
        </p>
       </div>
      </article>
     </div>
     <script>
      var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}
     </script>
     <script>
      var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))
     </script>
    </div>
    <button class="md-top md-icon" data-md-component="top" hidden="" type="button">
     <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
      <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z">
      </path>
     </svg>
     Back to top
    </button>
   </main>
   <footer class="md-footer">
    <div class="md-footer-meta md-typeset">
     <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
       <div class="md-copyright__highlight">
        <ul class="global-footer__links">
         <li>
          <a href="https://www.nvidia.com/en-us/about-nvidia/privacy-policy/" target="_blank">
           Privacy Policy
          </a>
         </li>
         <li>
          <a href="https://www.nvidia.com/en-us/privacy-center/" target="_blank">
           Manage My Privacy
          </a>
         </li>
         <li>
          <a href="https://www.nvidia.com/en-us/preferences/email-preferences/" target="_blank">
           Do Not Sell or Share My Data
          </a>
         </li>
         <li>
          <a href="https://www.nvidia.com/en-us/about-nvidia/legal-info/" target="_blank">
           Legal
          </a>
         </li>
         <li>
          <a href="https://www.nvidia.com/en-us/about-nvidia/accessibility/" target="_blank">
           Accessibility
          </a>
         </li>
         <li>
          <a href="https://www.nvidia.com/en-us/about-nvidia/company-policies/" target="_self">
           Corporate Policies
          </a>
         </li>
         <li>
          <a href="https://www.nvidia.com/en-us/product-security/" target="_blank">
           Product Security
          </a>
         </li>
         <li>
          <a href="https://www.nvidia.com/en-us/contact/" target="_blank">
           Contact
          </a>
         </li>
        </ul>
        <div class="global-footer__copyright">
         Copyright © 2024 NVIDIA Corporation
        </div>
       </div>
      </div>
     </div>
    </div>
   </footer>
  </div>
  <div class="md-dialog" data-md-component="dialog">
   <div class="md-dialog__inner md-typeset">
   </div>
  </div>
  <script id="__config" type="application/json">
   {"base": ".", "features": ["navigation.indexes", "navigation.expand", "navigation.tabs", "navigation.tabs.sticky", "navigation.top", "content.tabs.link", "content.code.copy", "announce.dismiss"], "search": "assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}
  </script>
  <!-- OneTrust Cookies Consent Notice start for www.jetson-ai-lab.com -->
  <script charset="UTF-8" data-domain-script="018e2d65-efdf-7071-b793-f15ccf25c234" src="https://cdn.cookielaw.org/scripttemplates/otSDKStub.js" type="text/javascript">
  </script>
  <script type="text/javascript">
   function OptanonWrapper() {        
        var event = new Event('bannerLoaded');
        window.dispatchEvent(event);
    }
  </script>
  <!-- OneTrust Cookies Consent Notice end for www.jetson-ai-lab.com -->
  <script src="https://images.nvidia.com/aem-dam/Solutions/ot-js/ot-custom.js" type="text/javascript">
  </script>
  <script src="//assets.adobedtm.com/5d4962a43b79/814eb6e9b4e1/launch-4bc07f1e0b0b.min.js">
  </script>
  <script src="assets/javascripts/bundle.f55a23d4.min.js">
  </script>
  <script>
   window._6si = window._6si || [];
  window._6si.push(['enableEventTracking', true]);
  window._6si.push(['setToken', 'eb417ec30d332e34d732e2916f185311']);
  window._6si.push(['setEndpoint', 'b.6sc.co']);
  window._6si.push(['enableRetargeting', false]); 

  window._6si.push(['enableCompanyDetails', true]);
  window._6si.push(['setEpsilonKey', '6f578ba72568231347d1bddb7102e53695302c28']);

  (function() {
    var gd = document.createElement('script');
    gd.type = 'text/javascript';
    gd.async = true;
    gd.src = '//j.6sc.co/6si.min.js';
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gd, s);
  })();
  </script>
  <script type="text/javascript">
   _satellite.pageBottom();
  </script>
 </body>
</html>
